/*
 * Copyright 2021-2025 the original author or authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      https://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package dk.trustworks.essentials.components.queue.postgresql;

import com.fasterxml.jackson.annotation.*;
import com.fasterxml.jackson.databind.*;
import com.fasterxml.jackson.databind.json.JsonMapper;
import com.fasterxml.jackson.datatype.jdk8.Jdk8Module;
import com.fasterxml.jackson.datatype.jsr310.JavaTimeModule;
import dk.trustworks.essentials.components.foundation.IOExceptionUtil;
import dk.trustworks.essentials.components.foundation.json.*;
import dk.trustworks.essentials.components.foundation.messaging.queue.*;
import dk.trustworks.essentials.components.foundation.messaging.queue.operations.*;
import dk.trustworks.essentials.components.foundation.postgresql.*;
import dk.trustworks.essentials.components.foundation.transaction.*;
import dk.trustworks.essentials.components.foundation.transaction.jdbi.*;
import dk.trustworks.essentials.components.queue.postgresql.jdbi.*;
import dk.trustworks.essentials.jackson.immutable.EssentialsImmutableJacksonModule;
import dk.trustworks.essentials.jackson.types.EssentialTypesJacksonModule;
import dk.trustworks.essentials.reactive.*;
import dk.trustworks.essentials.shared.Exceptions;
import dk.trustworks.essentials.shared.collections.Lists;
import dk.trustworks.essentials.shared.interceptor.InterceptorChain;
import org.jdbi.v3.core.Handle;
import org.slf4j.*;

import java.sql.Types;
import java.time.*;
import java.util.*;
import java.util.concurrent.*;
import java.util.function.*;
import java.util.stream.Collectors;

import static dk.trustworks.essentials.shared.Exceptions.rethrowIfCriticalError;
import static dk.trustworks.essentials.shared.FailFast.*;
import static dk.trustworks.essentials.shared.MessageFormatter.NamedArgumentBinding.arg;
import static dk.trustworks.essentials.shared.MessageFormatter.*;
import static dk.trustworks.essentials.shared.interceptor.DefaultInterceptorChain.sortInterceptorsByOrder;
import static dk.trustworks.essentials.shared.interceptor.InterceptorChain.newInterceptorChainForOperation;

/**
 * Postgresql version of the {@link DurableQueues} concept.<br>
 * Works together with {@link UnitOfWorkFactory} in order to support queuing message together with business logic (such as failing to handle an Event, etc.)<br>
 * <br>
 * Per default this implementation uses the centralized message fetcher, {@link CentralizedMessageFetcher}, to optimize database operations
 * and supports batch fetching of messages across multiple queues.<br>
 * <u>Security</u><br>
 * {@link DurableQueues} allows the user of the component to override the {@link #getSharedQueueTableName()}, which is the name of the table that will contain all messages (across all {@link QueueName}'s)<br>
 * <strong>Note:</strong><br>
 * To support customization of storage table name, the {@code sharedQueueTableName} will be directly used in constructing SQL statements
 * through string concatenation, which exposes the component to SQL injection attacks.<br>
 * <br>
 * <strong>Security Note:</strong><br>
 * <b>It is the responsibility of the user of this component to sanitize the {@code sharedQueueTableName}
 * to ensure the security of all the SQL statements generated by this component.</b><br>
 * The {@link PostgresqlDurableQueues} component will
 * call the {@link PostgresqlUtil#checkIsValidTableOrColumnName(String)} method to validate the table name as a first line of defense.<br>
 * The {@link PostgresqlUtil#checkIsValidTableOrColumnName(String)} provides an initial layer of defense against SQL injection by applying naming conventions intended to reduce the risk of malicious input.<br>
 * However, Essentials components as well as {@link PostgresqlUtil#checkIsValidTableOrColumnName(String)} does not offer exhaustive protection, nor does it assure the complete security of the resulting SQL against SQL injection threats.<br>
 * <b>The responsibility for implementing protective measures against SQL Injection lies exclusively with the users/developers using the Essentials components and its supporting classes.</b><br>
 * Users must ensure thorough sanitization and validation of API input parameters,  column, table, and index names.<br>
 * Insufficient attention to these practices may leave the application vulnerable to SQL injection, potentially endangering the security and integrity of the database.<br>
 * <b>The responsibility for implementing protective measures against SQL Injection lies exclusively with the users/developers using the Essentials components and its supporting classes</b>.<br>
 * Users must ensure thorough sanitization and validation of API input parameters,  column, table, and index names.<br>
 * Insufficient attention to these practices may leave the application vulnerable to SQL injection, potentially endangering the security and integrity of the database.<br>
 * <br>
 * It is highly recommended that the {@code sharedQueueTableName} value is only derived from a controlled and trusted source.<br>
 * To mitigate the risk of SQL injection attacks, external or untrusted inputs should never directly provide the {@code sharedQueueTableName} value.<br>
 */
public final class PostgresqlDurableQueues implements BatchMessageFetchingCapableDurableQueues {
    private static final Logger log                               = LoggerFactory.getLogger(PostgresqlDurableQueues.class);
    public static final  String DEFAULT_DURABLE_QUEUES_TABLE_NAME = "durable_queues";
    private static final Object NO_PAYLOAD                        = new Object();

    private final HandleAwareUnitOfWorkFactory<? extends HandleAwareUnitOfWork>           unitOfWorkFactory;
    private final JSONSerializer                                                          jsonSerializer;
    private final String                                                                  sharedQueueTableName;
    private final ConcurrentMap<QueueName, CentralizedMessageFetcherDurableQueueConsumer> durableQueueConsumers            = new ConcurrentHashMap<>();
    private final ConcurrentMap<QueueName, PostgresqlDurableQueueConsumer>                traditionalDurableQueueConsumers = new ConcurrentHashMap<>();
    private final QueuedMessageRowMapper                                                  queuedMessageMapper;
    private final List<DurableQueuesInterceptor>                                          interceptors                     = new CopyOnWriteArrayList<>();
    private final Optional<MultiTableChangeListener<TableChangeNotification>>             multiTableChangeListener;
    private final Function<ConsumeFromQueue, QueuePollingOptimizer>                       queuePollingOptimizerFactory;
    private final TransactionalMode                                                       transactionalMode;
    private       CentralizedMessageFetcher                                               centralizedMessageFetcher;
    /**
     * Flag indicating whether to use the {@link CentralizedMessageFetcher} or the legacy
     * {@link DefaultDurableQueueConsumer} approach for handling messages
     */
    private final boolean                                                                 useCentralizedMessageFetcher;
    private final boolean                                                                 useOrderedUnorderedQuery;

    private   Function<QueueName, QueuePollingOptimizer> centralizedQueuePollingOptimizerFactory;
    /**
     * Only used if {@link #transactionalMode} has value {@link TransactionalMode#SingleOperationTransaction}
     */
    private   int                                        messageHandlingTimeoutMs;
    /**
     * Contains the timestamp of the last performed {@link #resetMessagesStuckBeingDelivered(QueueName)} check<br>
     * Only used if {@link #transactionalMode} has value {@link TransactionalMode#SingleOperationTransaction}
     */
    protected ConcurrentMap<QueueName, Instant>          lastResetStuckMessagesCheckTimestamps = new ConcurrentHashMap<>();

    private volatile boolean started;

    public static PostgresqlDurableQueuesBuilder builder() {
        return new PostgresqlDurableQueuesBuilder();
    }

    /**
     * Create {@link DurableQueues} with sharedQueueTableName: {@value DEFAULT_DURABLE_QUEUES_TABLE_NAME} and the default {@link JacksonJSONSerializer} using {@link #createDefaultObjectMapper()}
     * configuration<br>
     * Uses the centralized message fetcher with a 20ms polling interval
     *
     * @param unitOfWorkFactory the {@link UnitOfWorkFactory} needed to access the database
     */
    public PostgresqlDurableQueues(HandleAwareUnitOfWorkFactory<? extends HandleAwareUnitOfWork> unitOfWorkFactory) {
        this(unitOfWorkFactory,
             new JacksonJSONSerializer(createDefaultObjectMapper()),
             DEFAULT_DURABLE_QUEUES_TABLE_NAME,
             null,
             null);
    }

    /**
     * Create {@link DurableQueues} with sharedQueueTableName: {@value DEFAULT_DURABLE_QUEUES_TABLE_NAME} and the default {@link JacksonJSONSerializer} using {@link #createDefaultObjectMapper()}
     * configuration<br>
     * Uses the centralized message fetcher with a 20ms polling interval
     *
     * @param unitOfWorkFactory            the {@link UnitOfWorkFactory} needed to access the database
     * @param queuePollingOptimizerFactory optional {@link QueuePollingOptimizer} factory that creates a {@link QueuePollingOptimizer} per {@link ConsumeFromQueue} command -
     *                                     if set to null {@link #createQueuePollingOptimizerFor(ConsumeFromQueue)} is used instead
     */
    public PostgresqlDurableQueues(HandleAwareUnitOfWorkFactory<? extends HandleAwareUnitOfWork> unitOfWorkFactory,
                                   Function<ConsumeFromQueue, QueuePollingOptimizer> queuePollingOptimizerFactory) {
        this(unitOfWorkFactory,
             new JacksonJSONSerializer(createDefaultObjectMapper()),
             DEFAULT_DURABLE_QUEUES_TABLE_NAME,
             null,
             queuePollingOptimizerFactory);
    }

    /**
     * Create {@link DurableQueues} with custom jsonSerializer with sharedQueueTableName: {@value DEFAULT_DURABLE_QUEUES_TABLE_NAME}<br>
     * Uses the centralized message fetcher with a 20ms polling interval
     *
     * @param unitOfWorkFactory the {@link UnitOfWorkFactory} needed to access the database
     * @param jsonSerializer    the {@link JSONSerializer} that is used to serialize/deserialize message payloads
     */
    public PostgresqlDurableQueues(HandleAwareUnitOfWorkFactory<? extends HandleAwareUnitOfWork> unitOfWorkFactory,
                                   JSONSerializer jsonSerializer) {
        this(unitOfWorkFactory,
             jsonSerializer,
             DEFAULT_DURABLE_QUEUES_TABLE_NAME,
             null,
             null);
    }

    /**
     * Create {@link DurableQueues} with custom jsonSerializer with sharedQueueTableName: {@value DEFAULT_DURABLE_QUEUES_TABLE_NAME}<br>
     * Uses the centralized message fetcher with a 20ms polling interval
     *
     * @param unitOfWorkFactory            the {@link UnitOfWorkFactory} needed to access the database
     * @param jsonSerializer               the {@link JSONSerializer} that is used to serialize/deserialize message payloads
     * @param queuePollingOptimizerFactory optional {@link QueuePollingOptimizer} factory that creates a {@link QueuePollingOptimizer} per {@link ConsumeFromQueue} command -
     *                                     if set to null {@link #createQueuePollingOptimizerFor(ConsumeFromQueue)} is used instead
     */
    public PostgresqlDurableQueues(HandleAwareUnitOfWorkFactory<? extends HandleAwareUnitOfWork> unitOfWorkFactory,
                                   JSONSerializer jsonSerializer,
                                   Function<ConsumeFromQueue, QueuePollingOptimizer> queuePollingOptimizerFactory) {
        this(unitOfWorkFactory,
             jsonSerializer,
             DEFAULT_DURABLE_QUEUES_TABLE_NAME,
             null,
             queuePollingOptimizerFactory);
    }

    /**
     * Create {@link DurableQueues} with custom jsonSerializer and sharedQueueTableName<br>
     * Uses the centralized message fetcher with a 20ms polling interval
     *
     * @param unitOfWorkFactory            the {@link UnitOfWorkFactory} needed to access the database
     * @param jsonSerializer               the {@link JSONSerializer} that is used to serialize/deserialize message payloads
     * @param sharedQueueTableName         the name of the table that will contain all messages (across all {@link QueueName}'s)<br>
     *                                     <strong>Note:</strong><br>
     *                                     To support customization of storage table name, the {@code sharedQueueTableName} will be directly used in constructing SQL statements
     *                                     through string concatenation, which exposes the component to SQL injection attacks.<br>
     *                                     <br>
     *                                     <strong>Security Note:</strong><br>
     *                                     <b>It is the responsibility of the user of this component to sanitize the {@code sharedQueueTableName}
     *                                     to ensure the security of all the SQL statements generated by this component.</b><br>
     *                                     The {@link PostgresqlDurableQueues} component will
     *                                     call the {@link PostgresqlUtil#checkIsValidTableOrColumnName(String)} method to validate the table name as a first line of defense.<br>
     *                                     The {@link PostgresqlUtil#checkIsValidTableOrColumnName(String)} provides an initial layer of defense against SQL injection by applying naming conventions intended to reduce the risk of malicious input.<br>
     *                                     However, Essentials components as well as {@link PostgresqlUtil#checkIsValidTableOrColumnName(String)} does not offer exhaustive protection, nor does it assure the complete security of the resulting SQL against SQL injection threats.<br>
     *                                     <b>The responsibility for implementing protective measures against SQL Injection lies exclusively with the users/developers using the Essentials components and its supporting classes</b>.<br>
     *                                     Users must ensure thorough sanitization and validation of API input parameters,  column, table, and index names.<br>
     *                                     Insufficient attention to these practices may leave the application vulnerable to SQL injection, potentially endangering the security and integrity of the database.<br>
     *                                     <br>
     *                                     It is highly recommended that the {@code sharedQueueTableName} value is only derived from a controlled and trusted source.<br>
     *                                     To mitigate the risk of SQL injection attacks, external or untrusted inputs should never directly provide the {@code sharedQueueTableName} value.<br>
     * @param multiTableChangeListener     optional {@link MultiTableChangeListener} that allows {@link PostgresqlDurableQueues} to use {@link QueuePollingOptimizer}
     * @param queuePollingOptimizerFactory optional {@link QueuePollingOptimizer} factory that creates a {@link QueuePollingOptimizer} per {@link ConsumeFromQueue} command -
     *                                     if set to null {@link #createQueuePollingOptimizerFor(ConsumeFromQueue)} is used instead
     */
    public PostgresqlDurableQueues(HandleAwareUnitOfWorkFactory<? extends HandleAwareUnitOfWork> unitOfWorkFactory,
                                   JSONSerializer jsonSerializer,
                                   String sharedQueueTableName,
                                   MultiTableChangeListener<TableChangeNotification> multiTableChangeListener,
                                   Function<ConsumeFromQueue, QueuePollingOptimizer> queuePollingOptimizerFactory) {
        this(unitOfWorkFactory,
             jsonSerializer,
             sharedQueueTableName,
             multiTableChangeListener,
             queuePollingOptimizerFactory,
             TransactionalMode.FullyTransactional,
             null);
    }

    /**
     * Create {@link DurableQueues} with custom jsonSerializer and sharedQueueTableName<br>
     * Uses the centralized message fetcher with a 20ms polling interval
     * <br>
     *
     * @param unitOfWorkFactory            the {@link UnitOfWorkFactory} needed to access the database
     * @param jsonSerializer               the {@link JSONSerializer} that is used to serialize/deserialize message payloads
     * @param sharedQueueTableName         the name of the table that will contain all messages (across all {@link QueueName}'s)<br>
     *                                     <strong>Note:</strong><br>
     *                                     To support customization of storage table name, the {@code sharedQueueTableName} will be directly used in constructing SQL statements
     *                                     through string concatenation, which exposes the component to SQL injection attacks.<br>
     *                                     <br>
     *                                     <strong>Security Note:</strong><br>
     *                                     <b>It is the responsibility of the user of this component to sanitize the {@code sharedQueueTableName}
     *                                     to ensure the security of all the SQL statements generated by this component.</b><br>
     *                                     The {@link PostgresqlDurableQueues} component will
     *                                     call the {@link PostgresqlUtil#checkIsValidTableOrColumnName(String)} method to validate the table name as a first line of defense.<br>
     *                                     The {@link PostgresqlUtil#checkIsValidTableOrColumnName(String)} provides an initial layer of defense against SQL injection by applying naming conventions intended to reduce the risk of malicious input.<br>
     *                                     However, Essentials components as well as {@link PostgresqlUtil#checkIsValidTableOrColumnName(String)} does not offer exhaustive protection, nor does it assure the complete security of the resulting SQL against SQL injection threats.<br>
     *                                     <b>The responsibility for implementing protective measures against SQL Injection lies exclusively with the users/developers using the Essentials components and its supporting classes</b>.<br>
     *                                     Users must ensure thorough sanitization and validation of API input parameters,  column, table, and index names.<br>
     *                                     Insufficient attention to these practices may leave the application vulnerable to SQL injection, potentially endangering the security and integrity of the database.<br>
     *                                     <br>
     *                                     It is highly recommended that the {@code sharedQueueTableName} value is only derived from a controlled and trusted source.<br>
     *                                     To mitigate the risk of SQL injection attacks, external or untrusted inputs should never directly provide the {@code sharedQueueTableName} value.<br>
     * @param multiTableChangeListener     optional {@link MultiTableChangeListener} that allows {@link PostgresqlDurableQueues} to use {@link QueuePollingOptimizer}
     * @param queuePollingOptimizerFactory optional {@link QueuePollingOptimizer} factory that creates a {@link QueuePollingOptimizer} per {@link ConsumeFromQueue} command -
     *                                     if set to null {@link #createQueuePollingOptimizerFor(ConsumeFromQueue)} is used instead
     * @param transactionalMode            The {@link TransactionalMode} for this {@link DurableQueues} instance. If set to {@link TransactionalMode#SingleOperationTransaction}
     *                                     then the consumer MUST call the {@link DurableQueues#acknowledgeMessageAsHandled(AcknowledgeMessageAsHandled)} explicitly in a new {@link UnitOfWork}
     * @param messageHandlingTimeout       Only required if <code>transactionalMode</code> is {@link TransactionalMode#SingleOperationTransaction}.<br>
     *                                     The parameter defines the timeout for messages being delivered, but haven't yet been acknowledged.
     *                                     After this timeout the message delivery will be reset and the message will again be a candidate for delivery
     */
    public PostgresqlDurableQueues(HandleAwareUnitOfWorkFactory<? extends HandleAwareUnitOfWork> unitOfWorkFactory,
                                   JSONSerializer jsonSerializer,
                                   String sharedQueueTableName,
                                   MultiTableChangeListener<TableChangeNotification> multiTableChangeListener,
                                   Function<ConsumeFromQueue, QueuePollingOptimizer> queuePollingOptimizerFactory,
                                   TransactionalMode transactionalMode,
                                   Duration messageHandlingTimeout) {
        this(unitOfWorkFactory,
             jsonSerializer,
             sharedQueueTableName,
             multiTableChangeListener,
             queuePollingOptimizerFactory,
             transactionalMode,
             messageHandlingTimeout,
             true,  // Use centralized message fetcher by default
             Duration.ofMillis(20), // With a 20ms polling interval by default
             null,
             false);
    }

    /**
     * Create {@link DurableQueues} with custom jsonSerializer and sharedQueueTableName
     * <br>
     *
     * @param unitOfWorkFactory                        the {@link UnitOfWorkFactory} needed to access the database
     * @param jsonSerializer                           the {@link JSONSerializer} that is used to serialize/deserialize message payloads
     * @param sharedQueueTableName                     the name of the table that will contain all messages (across all {@link QueueName}'s)<br>
     *                                                 <strong>Note:</strong><br>
     *                                                 To support customization of storage table name, the {@code sharedQueueTableName} will be directly used in constructing SQL statements
     *                                                 through string concatenation, which exposes the component to SQL injection attacks.<br>
     *                                                 <br>
     *                                                 <strong>Security Note:</strong><br>
     *                                                 <b>It is the responsibility of the user of this component to sanitize the {@code sharedQueueTableName}
     *                                                 to ensure the security of all the SQL statements generated by this component.</b><br>
     *                                                 The {@link PostgresqlDurableQueues} component will
     *                                                 call the {@link PostgresqlUtil#checkIsValidTableOrColumnName(String)} method to validate the table name as a first line of defense.<br>
     *                                                 The {@link PostgresqlUtil#checkIsValidTableOrColumnName(String)} provides an initial layer of defense against SQL injection by applying naming conventions intended to reduce the risk of malicious input.<br>
     *                                                 However, Essentials components as well as {@link PostgresqlUtil#checkIsValidTableOrColumnName(String)} does not offer exhaustive protection, nor does it assure the complete security of the resulting SQL against SQL injection threats.<br>
     *                                                 <b>The responsibility for implementing protective measures against SQL Injection lies exclusively with the users/developers using the Essentials components and its supporting classes</b>.<br>
     *                                                 Users must ensure thorough sanitization and validation of API input parameters,  column, table, and index names.<br>
     *                                                 Insufficient attention to these practices may leave the application vulnerable to SQL injection, potentially endangering the security and integrity of the database.<br>
     *                                                 <br>
     *                                                 It is highly recommended that the {@code sharedQueueTableName} value is only derived from a controlled and trusted source.<br>
     *                                                 To mitigate the risk of SQL injection attacks, external or untrusted inputs should never directly provide the {@code sharedQueueTableName} value.<br>
     * @param multiTableChangeListener                 optional {@link MultiTableChangeListener} that allows {@link PostgresqlDurableQueues} to use {@link QueuePollingOptimizer}
     * @param queuePollingOptimizerFactory             optional {@link QueuePollingOptimizer} factory that creates a {@link QueuePollingOptimizer} per {@link ConsumeFromQueue} command -
     *                                                 if set to null {@link #createQueuePollingOptimizerFor(ConsumeFromQueue)} is used instead - not required when using the Centralized message fetcher
     * @param transactionalMode                        The {@link TransactionalMode} for this {@link DurableQueues} instance. If set to {@link TransactionalMode#SingleOperationTransaction}
     *                                                 then the consumer MUST call the {@link DurableQueues#acknowledgeMessageAsHandled(AcknowledgeMessageAsHandled)} explicitly in a new {@link UnitOfWork}
     * @param messageHandlingTimeout                   Only required if <code>transactionalMode</code> is {@link TransactionalMode#SingleOperationTransaction}.<br>
     *                                                 The parameter defines the timeout for messages being delivered, but haven't yet been acknowledged.
     *                                                 After this timeout the message delivery will be reset and the message will again be a candidate for delivery
     * @param useCentralizedMessageFetcher             Whether to use the {@link CentralizedMessageFetcher} (true) or fallback to the traditional {@link DefaultDurableQueueConsumer} (false).
     *                                                 The centralized fetcher optimizes message fetching across multiple queues.
     * @param centralizedMessageFetcherPollingInterval Set the polling interval for the {@link CentralizedMessageFetcher}.
     *                                                 This value determines how frequently the fetcher checks for new messages when none are immediately available.
     */
    public PostgresqlDurableQueues(HandleAwareUnitOfWorkFactory<? extends HandleAwareUnitOfWork> unitOfWorkFactory,
                                   JSONSerializer jsonSerializer,
                                   String sharedQueueTableName,
                                   MultiTableChangeListener<TableChangeNotification> multiTableChangeListener,
                                   Function<ConsumeFromQueue, QueuePollingOptimizer> queuePollingOptimizerFactory,
                                   TransactionalMode transactionalMode,
                                   Duration messageHandlingTimeout,
                                   boolean useCentralizedMessageFetcher,
                                   Duration centralizedMessageFetcherPollingInterval,
                                   Function<QueueName, QueuePollingOptimizer> centralizedQueuePollingOptimizerFactory,
                                   boolean useOrderedUnorderedQuery) {
        this.unitOfWorkFactory = requireNonNull(unitOfWorkFactory, "No unitOfWorkFactory instance provided");
        this.jsonSerializer = requireNonNull(jsonSerializer, "No jsonSerializer");
        this.sharedQueueTableName = requireNonNull(sharedQueueTableName, "No sharedQueueTableName provided").toLowerCase(Locale.ROOT);
        PostgresqlUtil.checkIsValidTableOrColumnName(sharedQueueTableName);
        this.useCentralizedMessageFetcher = useCentralizedMessageFetcher;
        this.useOrderedUnorderedQuery = useOrderedUnorderedQuery;

        // Create the message row mapper for mapping SQL results to QueuedMessage objects
        this.queuedMessageMapper = new QueuedMessageRowMapper(this::deserializeMessagePayload, this::deserializeMessageMetadata);

        this.multiTableChangeListener = Optional.ofNullable(multiTableChangeListener);
        this.queuePollingOptimizerFactory = queuePollingOptimizerFactory != null ? queuePollingOptimizerFactory : this::createQueuePollingOptimizerFor;
        this.transactionalMode = requireNonNull(transactionalMode, "No transactionalMode instance provided");

        // Initialize the centralized message fetcher
        if (useCentralizedMessageFetcher) {
            this.centralizedMessageFetcher = new CentralizedMessageFetcher(this,
                                                                           requireNonNull(centralizedMessageFetcherPollingInterval, "No centralizedMessageFetcherPollingInterval provided").toMillis(),
                                                                           interceptors);
            this.centralizedQueuePollingOptimizerFactory = centralizedQueuePollingOptimizerFactory != null ? centralizedQueuePollingOptimizerFactory : this::createCentralizedQueuePollingOptimizerFor;
        }

        if (transactionalMode == TransactionalMode.SingleOperationTransaction) {
            messageHandlingTimeoutMs = (int) requireNonNull(messageHandlingTimeout, "No messageHandlingTimeout provided").toMillis();
            addInterceptor(new SingleOperationTransactionDurableQueuesInterceptor(unitOfWorkFactory));
        }
        this.multiTableChangeListener.ifPresent(listener -> listener.addDuplicationFilterAsFirst(new QueueNameDuplicationFilter()));

        initializeQueueTables();
    }

    private void initializeQueueTables() {
        PostgresqlUtil.checkIsValidTableOrColumnName(sharedQueueTableName);
        unitOfWorkFactory.usingUnitOfWork(handleAwareUnitOfWork -> {
            handleAwareUnitOfWork.handle().getJdbi().registerArgument(new QueueNameArgumentFactory());
            handleAwareUnitOfWork.handle().getJdbi().registerColumnMapper(new QueueNameColumnMapper());
            handleAwareUnitOfWork.handle().getJdbi().registerArgument(new QueueEntryIdArgumentFactory());
            handleAwareUnitOfWork.handle().getJdbi().registerColumnMapper(new QueueEntryIdColumnMapper());
            handleAwareUnitOfWork.handle().execute(bind("CREATE TABLE IF NOT EXISTS {:tableName} (\n" +
                                                                "  id                     TEXT PRIMARY KEY,\n" +
                                                                "  queue_name             TEXT NOT NULL,\n" +
                                                                "  message_payload        JSONB NOT NULL,\n" +
                                                                "  message_payload_type   TEXT NOT NULL,\n" +
                                                                "  added_ts               TIMESTAMPTZ NOT NULL,\n" +
                                                                "  next_delivery_ts       TIMESTAMPTZ,\n" +
                                                                "  delivery_ts            TIMESTAMPTZ DEFAULT NULL,\n" +
                                                                "  total_attempts         INTEGER DEFAULT 0,\n" +
                                                                "  redelivery_attempts    INTEGER DEFAULT 0,\n" +
                                                                "  last_delivery_error    TEXT DEFAULT NULL,\n" +
                                                                "  is_being_delivered     BOOLEAN DEFAULT FALSE,\n" +
                                                                "  is_dead_letter_message BOOLEAN NOT NULL DEFAULT FALSE,\n" +
                                                                "  meta_data              JSONB DEFAULT NULL,\n" +
                                                                "  delivery_mode          TEXT NOT NULL,\n" +
                                                                "  key                    TEXT DEFAULT NULL,\n" +
                                                                "  key_order              BIGINT DEFAULT -1\n" +
                                                                ")",
                                                        arg("tableName", sharedQueueTableName))
                                                  );
            log.info("Ensured Durable Queues table '{}' exists", sharedQueueTableName);

            dropIndex("DROP INDEX IF EXISTS idx_{:tableName}_queue_name",
                      handleAwareUnitOfWork.handle());
            dropIndex("DROP INDEX IF EXISTS idx_{:tableName}_next_delivery_ts",
                      handleAwareUnitOfWork.handle());
            dropIndex("DROP INDEX IF EXISTS idx_{:tableName}_is_dead_letter_message",
                      handleAwareUnitOfWork.handle());
            dropIndex("DROP INDEX IF EXISTS idx_{:tableName}_is_being_delivered",
                      handleAwareUnitOfWork.handle());


            createIndex("CREATE INDEX IF NOT EXISTS idx_{:tableName}_ordered_msg ON {:tableName} (queue_name, key, key_order)",
                        handleAwareUnitOfWork.handle());
            createIndex("CREATE INDEX IF NOT EXISTS idx_{:tableName}_next_msg ON {:tableName} (queue_name, is_dead_letter_message, is_being_delivered, next_delivery_ts)",
                        handleAwareUnitOfWork.handle());
            createIndex("""
                        CREATE INDEX IF NOT EXISTS idx_{:tableName}_ready ON {:tableName} (
                            queue_name,
                            next_delivery_ts,
                            key,
                            key_order
                        )
                        WHERE
                            is_dead_letter_message = FALSE
                            AND is_being_delivered = FALSE
                        """,
                        handleAwareUnitOfWork.handle());
            createIndex("""
                        CREATE INDEX IF NOT EXISTS idx_{:tableName}_ordered_ready
                          ON {:tableName} (key, queue_name, key_order, next_delivery_ts)
                          INCLUDE (id)
                          WHERE key IS NOT NULL
                            AND NOT is_dead_letter_message
                            AND NOT is_being_delivered
                        """,
                        handleAwareUnitOfWork.handle());

            createIndex("""
                        CREATE INDEX IF NOT EXISTS idx_{:tableName}_unordered_ready
                          ON {:tableName} (queue_name, next_delivery_ts)
                          INCLUDE (id)
                          WHERE key IS NULL
                            AND NOT is_dead_letter_message
                            AND NOT is_being_delivered
                        """,
                        handleAwareUnitOfWork.handle());

            createIndex("""
                        CREATE INDEX IF NOT EXISTS idx_{:tableName}_ordered_head
                          ON {:tableName} (queue_name, key_order, next_delivery_ts)
                          INCLUDE (id)
                          WHERE key IS NOT NULL
                            AND is_dead_letter_message = FALSE
                            AND is_being_delivered     = FALSE;
                        """,
                        handleAwareUnitOfWork.handle());

            multiTableChangeListener.ifPresent(listener -> {
                ListenNotify.addChangeNotificationTriggerToTable(handleAwareUnitOfWork.handle(),
                                                                 sharedQueueTableName,
                                                                 List.of(ListenNotify.SqlOperation.INSERT, ListenNotify.SqlOperation.UPDATE),
                                                                 "id", "queue_name", "added_ts", "next_delivery_ts", "delivery_ts", "is_dead_letter_message", "is_being_delivered");
            });
        });
    }

    private void createIndex(String indexStatement, Handle handle) {
        PostgresqlUtil.checkIsValidTableOrColumnName(sharedQueueTableName);
        handle.execute(bind(indexStatement,
                            arg("tableName", sharedQueueTableName))
                      );
    }

    private void dropIndex(String indexStatement, Handle handle) {
        PostgresqlUtil.checkIsValidTableOrColumnName(sharedQueueTableName);
        handle.execute(bind(indexStatement,
                            arg("tableName", sharedQueueTableName))
                      );
    }

    /**
     * The name of the shared table where all queue messages are stored
     *
     * @return the name of the shared table where all queue messages are stored
     */
    public String getSharedQueueTableName() {
        return sharedQueueTableName;
    }

    public List<DurableQueuesInterceptor> getInterceptors() {
        return Collections.unmodifiableList(interceptors);
    }

    @Override
    public void start() {
        if (!started) {
            started = true;
            log.info("Starting");
            PostgresqlUtil.checkIsValidTableOrColumnName(sharedQueueTableName);
            interceptors.forEach(durableQueuesInterceptor -> durableQueuesInterceptor.setDurableQueues(this));
            sortInterceptorsByOrder(interceptors);

            if (useCentralizedMessageFetcher) {
                // Start the centralized message fetcher first
                centralizedMessageFetcher.start();

                // Then start all centralized consumers
                durableQueueConsumers.values().forEach(CentralizedMessageFetcherDurableQueueConsumer::start);
            } else {
                // Start all traditional consumers
                traditionalDurableQueueConsumers.values().forEach(PostgresqlDurableQueueConsumer::start);
            }

            multiTableChangeListener.ifPresent(listener -> {
                listener.listenToNotificationsFor(sharedQueueTableName,
                                                  QueueTableNotification.class);
                listener.getEventBus().addAsyncSubscriber(new AnnotatedEventHandler() {
                    @Handler
                    void handle(QueueTableNotification e) {
                        try {
                            log.trace("[{}] Received Message-Added {} with id '{}'",
                                      e.queueName,
                                      e.getClass().getSimpleName(),
                                      e.id);
                            var queueName = QueueName.of(e.queueName);

                            if (useCentralizedMessageFetcher) {
                                // For centralized consumers, simply log the notification
                                durableQueueConsumers.values()
                                                     .stream()
                                                     .filter(durableQueueConsumer -> durableQueueConsumer.queueName().equals(queueName))
                                                     .forEach(durableQueueConsumer -> {
                                                         // Just notify that a message was added, no need to process it directly
                                                         // The centralized fetcher will pick it up
                                                         log.debug("[{}] New message notification received with QueueEntryId '{}'", queueName, e.id);
                                                         var queuedMessage = createDefaultQueuedMessage(e, queueName);
                                                         // Use the notification interface to optimize polling
                                                         durableQueueConsumer.messageAdded(queuedMessage);
                                                     });
                            } else {
                                // For traditional consumers, pass the notification to the consumer to optimize polling
                                traditionalDurableQueueConsumers.values()
                                                                .stream()
                                                                .filter(durableQueueConsumer -> durableQueueConsumer.queueName().equals(queueName))
                                                                .forEach(durableQueueConsumer -> {
                                                                    // Create a stub QueuedMessage just for notification purposes
                                                                    var queuedMessage = createDefaultQueuedMessage(e, queueName);
                                                                    // Use the notification interface to optimize polling
                                                                    durableQueueConsumer.messageAdded(queuedMessage);
                                                                });
                            }
                        } catch (Exception ex) {
                            log.error("Error occurred while handling notification", ex);
                        }
                    }
                });
            });

            log.info("Started");
        }
    }

    private static DefaultQueuedMessage createDefaultQueuedMessage(QueueTableNotification e, QueueName queueName) {
        return new DefaultQueuedMessage(QueueEntryId.of(String.valueOf(e.id)),
                                        queueName,
                                        Message.of(NO_PAYLOAD),
                                        e.addedTimestamp,
                                        e.nextDeliveryTimestamp,
                                        e.deliveryTimestamp,
                                        null,
                                        -1,
                                        -1,
                                        e.isDeadLetterMessage,
                                        e.isBeingDelivered);
    }

    @Override
    public void stop() {
        if (started) {
            log.info("Stopping");
            PostgresqlUtil.checkIsValidTableOrColumnName(sharedQueueTableName);

            if (useCentralizedMessageFetcher) {
                // Stop all centralized consumer instances first
                durableQueueConsumers.values().forEach(consumer -> {
                    try {
                        consumer.stop();
                    } catch (Exception ex) {
                        if (IOExceptionUtil.isIOException(ex)) {
                            log.debug("Error occurred while stopping CentralizedMessageFetcherDurableQueueConsumer", ex);
                        } else {
                            log.error("Error occurred while stopping CentralizedMessageFetcherDurableQueueConsumer", ex);
                        }
                    }
                });

                // Stop the centralized message fetcher
                try {
                    centralizedMessageFetcher.stop();
                } catch (Exception ex) {
                    if (IOExceptionUtil.isIOException(ex)) {
                        log.debug("Error occurred while stopping CentralizedMessageFetcher", ex);
                    } else {
                        log.error("Error occurred while stopping CentralizedMessageFetcher", ex);
                    }
                }
            } else {
                // Stop all traditional consumer instances
                traditionalDurableQueueConsumers.values().forEach(consumer -> {
                    try {
                        consumer.stop();
                    } catch (Exception ex) {
                        if (IOExceptionUtil.isIOException(ex)) {
                            log.debug("Error occurred while stopping PostgresqlDurableQueueConsumer", ex);
                        } else {
                            log.error("Error occurred while stopping PostgresqlDurableQueueConsumer", ex);
                        }
                    }
                });
            }

            multiTableChangeListener.ifPresent(listener -> {
                try {
                    listener.unlistenToNotificationsFor(sharedQueueTableName);
                } catch (Exception ex) {
                    if (IOExceptionUtil.isIOException(ex)) {
                        log.debug("Error occurred while performing unlistenToNotificationsFor '{}'", sharedQueueTableName, ex);
                    } else {
                        log.error("Error occurred while performing unlistenToNotificationsFor '{}'", sharedQueueTableName, ex);
                    }
                }
            });
            started = false;
            log.info("Stopped");
        }
    }

    @Override
    public boolean isStarted() {
        return started;
    }

    @Override
    public TransactionalMode getTransactionalMode() {
        return transactionalMode;
    }

    @Override
    public Optional<UnitOfWorkFactory<? extends UnitOfWork>> getUnitOfWorkFactory() {
        return Optional.ofNullable(unitOfWorkFactory);
    }

    public QueuedMessageRowMapper getQueuedMessageMapper() {
        return queuedMessageMapper;
    }

    @Override
    public Set<QueueName> getQueueNames() {
        var consumerQueueNames = getActiveQueueNames();
        var dbQueueNames = unitOfWorkFactory.withUnitOfWork(handleAwareUnitOfWork -> handleAwareUnitOfWork.handle()
                                                                                                          .createQuery(bind("SELECT distinct queue_name FROM {:tableName}",
                                                                                                                            arg("tableName", sharedQueueTableName)))
                                                                                                          .mapTo(QueueName.class)
                                                                                                          .set());
        dbQueueNames.addAll(consumerQueueNames);
        return dbQueueNames;
    }

    @Override
    public Set<QueueName> getActiveQueueNames() {
        // Combine queue names from both types of consumers
        Set<QueueName> allActiveQueueNames = new HashSet<>();
        allActiveQueueNames.addAll(durableQueueConsumers.keySet());
        allActiveQueueNames.addAll(traditionalDurableQueueConsumers.keySet());
        return allActiveQueueNames;
    }

    @Override
    public DurableQueueConsumer consumeFromQueue(ConsumeFromQueue operation) {
        requireNonNull(operation, "No operation provided");

        // Check if we already have a consumer for this queue
        if (durableQueueConsumers.containsKey(operation.queueName) ||
                traditionalDurableQueueConsumers.containsKey(operation.queueName)) {
            throw new DurableQueueException("There is already a DurableConsumer for this queue", operation.queueName);
        }

        operation.validate();

        if (useCentralizedMessageFetcher) {
            // Create and register a CentralizedMessageFetcherDurableQueueConsumer
            var queuePollingOptimizer = multiTableChangeListener.map(_ignore -> centralizedQueuePollingOptimizerFactory.apply(operation.getQueueName()))
                                                                .orElseGet(QueuePollingOptimizer::None);
            return durableQueueConsumers.computeIfAbsent(operation.queueName, _queueName -> {
                var consumer = (CentralizedMessageFetcherDurableQueueConsumer) newInterceptorChainForOperation(operation,
                                                                                                               interceptors,
                                                                                                               (interceptor, interceptorChain) -> interceptor.intercept(operation, interceptorChain),
                                                                                                               () -> (DurableQueueConsumer) new CentralizedMessageFetcherDurableQueueConsumer(
                                                                                                                       operation,
                                                                                                                       this,
                                                                                                                       this::removeQueueConsumer,
                                                                                                                       centralizedMessageFetcher,
                                                                                                                       queuePollingOptimizer)).proceed();
                if (started) {
                    consumer.start();
                }
                log.info("[{}] {} - {} {}",
                         operation.queueName,
                         operation.consumerName,
                         started ? "Started" : "Created",
                         consumer.getClass().getSimpleName()
                        );
                return consumer;
            });
        } else {
            // Create and register a traditional PostgresqlDurableQueueConsumer
            return traditionalDurableQueueConsumers.computeIfAbsent(operation.queueName, _queueName -> {
                var pollingIntervalMs = operation.getPollingInterval().toMillis();
                var queuePollingOptimizer = multiTableChangeListener.map(_ignore -> queuePollingOptimizerFactory.apply(operation))
                                                                    .orElseGet(QueuePollingOptimizer::None);

                var consumer = (PostgresqlDurableQueueConsumer) newInterceptorChainForOperation(operation,
                                                                                                interceptors,
                                                                                                (interceptor, interceptorChain) -> interceptor.intercept(operation, interceptorChain),
                                                                                                () -> (DurableQueueConsumer) new PostgresqlDurableQueueConsumer(
                                                                                                        operation,
                                                                                                        unitOfWorkFactory,
                                                                                                        this,
                                                                                                        this::removeQueueConsumer,
                                                                                                        pollingIntervalMs,
                                                                                                        queuePollingOptimizer,
                                                                                                        interceptors)).proceed();
                if (started) {
                    consumer.start();
                }
                log.info("[{}] {} - {} {}",
                         operation.queueName,
                         operation.consumerName,
                         started ? "Started" : "Created",
                         consumer.getClass().getSimpleName()
                        );
                return consumer;
            });
        }
    }

    /**
     * Override this method to provide another {@link QueuePollingOptimizer} than the default {@link QueuePollingOptimizer.SimpleQueuePollingOptimizer}<br>
     * Only called if the {@link PostgresqlDurableQueues} is configured with a {@link MultiTableChangeListener}
     *
     * @param operation the operation for which the {@link QueuePollingOptimizer} will be responsible
     * @return the {@link QueuePollingOptimizer}
     */
    protected QueuePollingOptimizer createQueuePollingOptimizerFor(ConsumeFromQueue operation) {
        var pollingIntervalMs = operation.getPollingInterval().toMillis();
        return new QueuePollingOptimizer.SimpleQueuePollingOptimizer(operation,
                                                                     (long) (pollingIntervalMs * 0.5d),
                                                                     pollingIntervalMs * 20);
    }

    /**
     * Override this method to provide another {@link QueuePollingOptimizer} than the default {@link CentralizedQueuePollingOptimizer}<br>
     * Only called if the {@link PostgresqlDurableQueues} is configured with a {@link MultiTableChangeListener}
     *
     * @param queueName the operation for which the {@link QueuePollingOptimizer} will be responsible
     * @return the {@link QueuePollingOptimizer}
     */
    protected QueuePollingOptimizer createCentralizedQueuePollingOptimizerFor(QueueName queueName) {
        if (!useCentralizedMessageFetcher) {
            throw new IllegalStateException("The CentralizedMessageFetcher is not enabled, so a custom QueuePollingOptimizer must be provided");
        }
        var pollingIntervalMs = centralizedMessageFetcher.getPollingIntervalMs();
        return new CentralizedQueuePollingOptimizer(queueName,
                                                    (long) (pollingIntervalMs * 0.5d),
                                                    pollingIntervalMs * 20,
                                                    1.5,
                                                    0.1
        );
    }

    final void removeQueueConsumer(DurableQueueConsumer durableQueueConsumer) {
        requireNonNull(durableQueueConsumer, "You must provide a durableQueueConsumer");
        requireFalse(durableQueueConsumer.isStarted(), msg("Cannot remove DurableQueueConsumer '{}' since it's started!", durableQueueConsumer.queueName()));
        var operation = new StopConsumingFromQueue(durableQueueConsumer);
        try {
            newInterceptorChainForOperation(operation,
                                            interceptors,
                                            (interceptor, interceptorChain) -> interceptor.intercept(operation, interceptorChain),
                                            () -> {
                                                var queueName = durableQueueConsumer.queueName();

                                                if (durableQueueConsumer instanceof CentralizedMessageFetcherDurableQueueConsumer) {
                                                    // Unregister from the centralized message fetcher
                                                    centralizedMessageFetcher.unregisterConsumer(queueName);

                                                    // Remove from the centralized consumers map
                                                    return (DurableQueueConsumer) durableQueueConsumers.remove(queueName);
                                                } else {
                                                    // This is a traditional consumer, remove from that map
                                                    return (DurableQueueConsumer) traditionalDurableQueueConsumers.remove(queueName);
                                                }
                                            })
                    .proceed();
        } catch (Exception e) {
            log.error(msg("Failed to perform {}", operation), e);
        }
    }

    @Override
    public final QueueEntryId queueMessage(QueueMessage operation) {
        requireNonNull(operation, "You must provide a QueueMessage instance");
        return newInterceptorChainForOperation(operation,
                                               interceptors,
                                               (interceptor, interceptorChain) -> interceptor.intercept(operation, interceptorChain),
                                               () -> queueMessage(operation.queueName,
                                                                  operation.getMessage(),
                                                                  false,
                                                                  operation.getCauseOfEnqueuing(),
                                                                  operation.getDeliveryDelay()))
                .proceed();
    }

    @Override
    public final QueueEntryId queueMessageAsDeadLetterMessage(QueueMessageAsDeadLetterMessage operation) {
        requireNonNull(operation, "You must provide a QueueMessageAsDeadLetterMessage instance");
        return newInterceptorChainForOperation(operation,
                                               interceptors,
                                               (interceptor, interceptorChain) -> interceptor.intercept(operation, interceptorChain),
                                               () -> queueMessage(operation.queueName,
                                                                  operation.getMessage(),
                                                                  true,
                                                                  Optional.ofNullable(operation.getCauseOfError()),
                                                                  Optional.empty()))
                .proceed();
    }

    protected final QueueEntryId queueMessage(QueueName queueName,
                                              Message message,
                                              boolean isDeadLetterMessage,
                                              Optional<Exception> causeOfEnqueuing,
                                              Optional<Duration> deliveryDelay) {
        requireNonNull(queueName, "You must provide a queueName");
        requireNonNull(message, "You must provide a message");
        requireNonNull(causeOfEnqueuing, "You must provide a causeOfEnqueuing option");
        requireNonNull(deliveryDelay, "You must provide a deliveryDelay option");

        var queueEntryId          = QueueEntryId.random();
        var addedTimestamp        = Instant.now();
        var nextDeliveryTimestamp = isDeadLetterMessage ? null : addedTimestamp.plus(deliveryDelay.orElse(Duration.ZERO));

        var isOrderedMessage = message instanceof OrderedMessage;
        log.trace("[{}:{}] Queuing {}{}message{} with nextDeliveryTimestamp {}",
                  queueName,
                  queueEntryId,
                  isDeadLetterMessage ? "Dead Letter " : "",
                  isOrderedMessage ? "Ordered " : "",
                  isOrderedMessage ? msg(" {}:{}", ((OrderedMessage) message).getKey(), ((OrderedMessage) message).getOrder()) : "",
                  nextDeliveryTimestamp);

        String jsonPayload;
        try {
            jsonPayload = jsonSerializer.serialize(message.getPayload());
        } catch (JSONSerializationException e) {
            throw new DurableQueueException(msg("Failed to serialize message payload of type", message.getPayload().getClass().getName()), e, queueName);
        }

        if (transactionalMode == TransactionalMode.FullyTransactional) {
            unitOfWorkFactory.getRequiredUnitOfWork();
        }

        // TODO: Future improvement: If queueing an OrderedMessage check if another OrderMessage related to the same key and a lower order is already marked as a dead letter message,
        //  in which case this message can be queued directly as a dead letter message
        unitOfWorkFactory.usingUnitOfWork(unitOfWork -> {
            var update = unitOfWork.handle().createUpdate(bind("INSERT INTO {:tableName} (\n" +
                                                                       "       id,\n" +
                                                                       "       queue_name,\n" +
                                                                       "       message_payload,\n" +
                                                                       "       message_payload_type,\n" +
                                                                       "       added_ts,\n" +
                                                                       "       next_delivery_ts,\n" +
                                                                       "       last_delivery_error,\n" +
                                                                       "       is_dead_letter_message,\n" +
                                                                       "       meta_data,\n" +
                                                                       "       delivery_mode,\n" +
                                                                       "       key,\n" +
                                                                       "       key_order\n" +
                                                                       "   ) VALUES (\n" +
                                                                       "       :id,\n" +
                                                                       "       :queueName,\n" +
                                                                       "       :message_payload::jsonb,\n" +
                                                                       "       :message_payload_type,\n" +
                                                                       "       :addedTimestamp,\n" +
                                                                       "       :nextDeliveryTimestamp,\n" +
                                                                       "       :lastDeliveryError,\n" +
                                                                       "       :isDeadLetterMessage,\n" +
                                                                       "       :metaData::jsonb,\n" +
                                                                       "       :deliveryMode,\n" +
                                                                       "       :key,\n" +
                                                                       "       :order\n" +
                                                                       "   )",
                                                               arg("tableName", sharedQueueTableName)))
                                   .bind("id", queueEntryId)
                                   .bind("queueName", queueName)
                                   .bind("message_payload", jsonPayload)
                                   .bind("message_payload_type", message.getPayload().getClass().getName())
                                   .bind("addedTimestamp", addedTimestamp)
                                   .bind("nextDeliveryTimestamp", nextDeliveryTimestamp)
                                   .bind("isDeadLetterMessage", isDeadLetterMessage);

            if (message instanceof OrderedMessage) {
                var orderedMessage = (OrderedMessage) message;
                requireNonNull(orderedMessage.getKey(), "An OrderedMessage requires a non null key");
                requireTrue(orderedMessage.getOrder() >= 0, "An OrderedMessage requires an order >= 0");
                update.bind("deliveryMode", QueuedMessage.DeliveryMode.IN_ORDER)
                      .bind("key", orderedMessage.getKey())
                      .bind("order", orderedMessage.getOrder());
            } else {
                update.bind("deliveryMode", QueuedMessage.DeliveryMode.NORMAL)
                      .bindNull("key", Types.VARCHAR)
                      .bind("order", -1L);

            }

            try {
                var jsonMetaData = jsonSerializer.serialize(message.getMetaData());
                update.bind("metaData", jsonMetaData);
            } catch (JSONSerializationException e) {
                throw new DurableQueueException("Failed to serialize message meta-data", e, queueName);
            }

            if (causeOfEnqueuing.isPresent()) {
                update.bind("lastDeliveryError", causeOfEnqueuing.map(Exceptions::getStackTrace).get());
            } else {
                update.bindNull("lastDeliveryError", Types.VARCHAR);
            }

            var numberOfRowsUpdated = update.execute();
            if (numberOfRowsUpdated == 0) {
                throw new DurableQueueException("Failed to insert message", queueName);
            }
        });
        log.debug("[{}:{}] Queued {}{}message{} with nextDeliveryTimestamp {}",
                  queueName,
                  queueEntryId,
                  isDeadLetterMessage ? "Dead Letter " : "",
                  isOrderedMessage ? "Ordered " : "",
                  isOrderedMessage ? msg(" {}:{}", ((OrderedMessage) message).getKey(), ((OrderedMessage) message).getOrder()) : "",
                  nextDeliveryTimestamp);
        return queueEntryId;
    }

    @Override
    public final List<QueueEntryId> queueMessages(QueueMessages operation) {
        requireNonNull(operation, "You must provide a QueueMessages instance");
        operation.validate();

        return newInterceptorChainForOperation(operation,
                                               interceptors,
                                               (interceptor, interceptorChain) -> interceptor.intercept(operation, interceptorChain),
                                               () -> {
                                                   var queueName             = operation.getQueueName();
                                                   var deliveryDelay         = operation.getDeliveryDelay();
                                                   var messages              = operation.getMessages();
                                                   var addedTimestamp        = Instant.now();
                                                   var nextDeliveryTimestamp = addedTimestamp.plus(deliveryDelay.orElse(Duration.ZERO));


                                                   var batch = unitOfWorkFactory.getRequiredUnitOfWork().handle().prepareBatch(bind("INSERT INTO {:tableName} (\n" +
                                                                                                                                            "       id,\n" +
                                                                                                                                            "       queue_name,\n" +
                                                                                                                                            "       message_payload,\n" +
                                                                                                                                            "       message_payload_type,\n" +
                                                                                                                                            "       added_ts,\n" +
                                                                                                                                            "       next_delivery_ts,\n" +
                                                                                                                                            "       last_delivery_error,\n" +
                                                                                                                                            "       is_dead_letter_message,\n" +
                                                                                                                                            "       is_being_delivered,\n" +
                                                                                                                                            "       meta_data,\n" +
                                                                                                                                            "       delivery_mode,\n" +
                                                                                                                                            "       key,\n" +
                                                                                                                                            "       key_order\n" +
                                                                                                                                            "   ) VALUES (\n" +
                                                                                                                                            "       :id,\n" +
                                                                                                                                            "       :queueName,\n" +
                                                                                                                                            "       :message_payload::jsonb,\n" +
                                                                                                                                            "       :message_payload_type,\n" +
                                                                                                                                            "       :addedTimestamp,\n" +
                                                                                                                                            "       :nextDeliveryTimestamp,\n" +
                                                                                                                                            "       :lastDeliveryError,\n" +
                                                                                                                                            "       :isDeadLetterMessage,\n" +
                                                                                                                                            "       :isBeingDelivered,\n" +
                                                                                                                                            "       :metaData::jsonb,\n" +
                                                                                                                                            "       :deliveryMode,\n" +
                                                                                                                                            "       :key,\n" +
                                                                                                                                            "       :order\n" +
                                                                                                                                            "   )",
                                                                                                                                    arg("tableName", sharedQueueTableName)));
                                                   var queueEntryIds = Lists.toIndexedStream(messages).map(indexedMessage -> {
                                                       var    message = indexedMessage._2;
                                                       String jsonPayload;
                                                       try {
                                                           jsonPayload = jsonSerializer.serialize(message.getPayload());
                                                       } catch (JSONSerializationException e) {
                                                           throw new DurableQueueException(msg("Failed to serialize message payload of type", message.getPayload().getClass().getName()), e, queueName);
                                                       }
                                                       var queueEntryId = QueueEntryId.random();
                                                       batch.bind("id", queueEntryId)
                                                            .bind("queueName", queueName)
                                                            .bind("message_payload", jsonPayload)
                                                            .bind("message_payload_type", message.getPayload().getClass().getName())
                                                            .bind("addedTimestamp", addedTimestamp)
                                                            .bind("nextDeliveryTimestamp", nextDeliveryTimestamp)
                                                            .bind("isDeadLetterMessage", false)
                                                            .bind("isBeingDelivered", false)
                                                            .bindNull("lastDeliveryError", Types.VARCHAR);

                                                       if (message instanceof OrderedMessage) {
                                                           var orderedMessage = (OrderedMessage) message;
                                                           requireNonNull(orderedMessage.getKey(), msg("[Index: {}] - OrderedMessage requires a non null key", indexedMessage._1));
                                                           requireTrue(orderedMessage.getOrder() >= 0, msg("[Index: {}] - OrderedMessage requires an order >= 0", indexedMessage._1));

                                                           batch.bind("deliveryMode", QueuedMessage.DeliveryMode.IN_ORDER)
                                                                .bind("key", orderedMessage.getKey())
                                                                .bind("order", orderedMessage.getOrder());
                                                       } else {
                                                           batch.bind("deliveryMode", QueuedMessage.DeliveryMode.NORMAL)
                                                                .bindNull("key", Types.VARCHAR)
                                                                .bind("order", -1L);
                                                       }

                                                       try {
                                                           var jsonMetaData = jsonSerializer.serialize(message.getMetaData());
                                                           batch.bind("metaData", jsonMetaData);
                                                       } catch (JSONSerializationException e) {
                                                           throw new DurableQueueException("Failed to serialize message meta-data", e, queueName);
                                                       }

                                                       batch.add();
                                                       return queueEntryId;
                                                   }).collect(Collectors.toList());

                                                   var numberOfRowsUpdated = Arrays.stream(batch.execute())
                                                                                   .reduce(Integer::sum).orElse(0);
                                                   if (numberOfRowsUpdated != messages.size()) {
                                                       throw new DurableQueueException(msg("Attempted to queue {} messages but only inserted {} messages", messages.size(), numberOfRowsUpdated),
                                                                                       queueName);
                                                   }

                                                   log.debug("[{}] Queued {} Messages with nextDeliveryTimestamp {} and entry-id's: {}",
                                                             queueName,
                                                             messages.size(),
                                                             nextDeliveryTimestamp,
                                                             queueEntryIds);
                                                   return queueEntryIds;
                                               }).proceed();
    }

    @Override
    public final Optional<QueuedMessage> retryMessage(RetryMessage operation) {
        requireNonNull(operation, "You must provide a RetryMessage instance");
        operation.validate();
        return newInterceptorChainForOperation(operation,
                                               interceptors,
                                               (interceptor, interceptorChain) -> interceptor.intercept(operation, interceptorChain),
                                               () -> {
                                                   var nextDeliveryTimestamp = Instant.now().plus(operation.getDeliveryDelay());
                                                   var result = unitOfWorkFactory.getRequiredUnitOfWork().handle().createQuery(bind("UPDATE {:tableName} SET\n" +
                                                                                                                                            "     next_delivery_ts = :nextDeliveryTimestamp,\n" +
                                                                                                                                            "     last_delivery_error = :lastDeliveryError,\n" +
                                                                                                                                            "     redelivery_attempts = redelivery_attempts + 1,\n" +
                                                                                                                                            "     is_being_delivered = FALSE,\n" +
                                                                                                                                            "     delivery_ts = NULL\n" +
                                                                                                                                            " WHERE id = :id\n" +
                                                                                                                                            " RETURNING *",
                                                                                                                                    arg("tableName", sharedQueueTableName)))
                                                                                 .bind("nextDeliveryTimestamp", nextDeliveryTimestamp)
                                                                                 .bind("lastDeliveryError", operation.getCauseForRetry() != null ? Exceptions.getStackTrace(operation.getCauseForRetry()) : RetryMessage.MANUALLY_REQUESTED_REDELIVERY)
                                                                                 .bind("id", operation.queueEntryId)
                                                                                 .map(queuedMessageMapper)
                                                                                 .findOne();
                                                   if (result.isPresent()) {
                                                       log.debug("Marked Message with id '{}' for Retry at {}. Message entry after update: {}", operation.queueEntryId, nextDeliveryTimestamp, result.get());
                                                       return result;
                                                   } else {
                                                       log.error("Failed to Mark Message with id '{}' for Retry", operation.queueEntryId);
                                                       return Optional.<QueuedMessage>empty();
                                                   }
                                               }).proceed();
    }


    @Override
    public final Optional<QueuedMessage> markAsDeadLetterMessage(MarkAsDeadLetterMessage operation) {
        requireNonNull(operation, "You must provide a MarkAsDeadLetterMessage instance");
        operation.validate();
        return newInterceptorChainForOperation(operation,
                                               interceptors,
                                               (interceptor, interceptorChain) -> interceptor.intercept(operation, interceptorChain),
                                               () -> {
                                                   var result = unitOfWorkFactory.getRequiredUnitOfWork().handle().createQuery(bind("UPDATE {:tableName} SET\n" +
                                                                                                                                            "     next_delivery_ts = NULL,\n" +
                                                                                                                                            "     last_delivery_error = :lastDeliveryError,\n" +
                                                                                                                                            "     is_dead_letter_message = TRUE,\n" +
                                                                                                                                            "     is_being_delivered = FALSE,\n" +
                                                                                                                                            "     delivery_ts = NULL\n" +
                                                                                                                                            " WHERE id = :id AND is_dead_letter_message = FALSE\n" +
                                                                                                                                            " RETURNING *",
                                                                                                                                    arg("tableName", sharedQueueTableName)))
                                                                                 .bind("lastDeliveryError", operation.getCauseForBeingMarkedAsDeadLetter())
                                                                                 .bind("id", operation.queueEntryId)
                                                                                 .map(queuedMessageMapper)
                                                                                 .findOne();
                                                   if (result.isPresent()) {
                                                       log.debug("Marked message with id '{}' as Dead Letter Message. Message entry after update: {}", operation.queueEntryId, result.get());
                                                       return result;
                                                   } else {
                                                       log.error("Failed to Mark as Message message with id '{}' as Dead Letter Message", operation.queueEntryId);
                                                       return Optional.<QueuedMessage>empty();
                                                   }
                                               }).proceed();
    }

    @Override
    public final Optional<QueuedMessage> resurrectDeadLetterMessage(ResurrectDeadLetterMessage operation) {
        requireNonNull(operation, "You must provide a ResurrectDeadLetterMessage instance");
        operation.validate();
        return newInterceptorChainForOperation(operation,
                                               interceptors,
                                               (interceptor, interceptorChain) -> interceptor.intercept(operation, interceptorChain),
                                               () -> {
                                                   var nextDeliveryTimestamp = Instant.now().plus(operation.getDeliveryDelay());
                                                   var result = unitOfWorkFactory.getRequiredUnitOfWork().handle().createQuery(bind("UPDATE {:tableName} SET\n" +
                                                                                                                                            "     next_delivery_ts = :nextDeliveryTimestamp,\n" +
                                                                                                                                            "     is_dead_letter_message = FALSE\n" +
                                                                                                                                            " WHERE id = :id AND " +
                                                                                                                                            "is_dead_letter_message = TRUE\n" +
                                                                                                                                            " RETURNING *",
                                                                                                                                    arg("tableName", sharedQueueTableName)))
                                                                                 .bind("nextDeliveryTimestamp", nextDeliveryTimestamp)
                                                                                 .bind("id", operation.queueEntryId)
                                                                                 .map(queuedMessageMapper)
                                                                                 .findOne();
                                                   if (result.isPresent()) {
                                                       var updateResult = result.get();

                                                       var isOrderedMessage = updateResult.getDeliveryMode() == QueuedMessage.DeliveryMode.IN_ORDER;
                                                       log.debug("[{}] Resurrected Dead Letter {}Message with id '{}' {} and nextDeliveryTimestamp: {}. Message entry after update: {}",
                                                                 updateResult.getQueueName(),
                                                                 isOrderedMessage ? "Ordered " : "",
                                                                 operation.getQueueEntryId(),
                                                                 isOrderedMessage ? "(key: " + ((OrderedMessage) updateResult).getKey() + ", order: " + ((OrderedMessage) updateResult).getOrder() + ")" : "",
                                                                 nextDeliveryTimestamp,
                                                                 updateResult);
                                                       return result;
                                                   } else {
                                                       log.error("Failed to resurrect Dead Letter Message with id '{}'", operation.queueEntryId);
                                                       return Optional.<QueuedMessage>empty();
                                                   }
                                               }).proceed();
    }

    @Override
    public final boolean acknowledgeMessageAsHandled(AcknowledgeMessageAsHandled operation) {
        requireNonNull(operation, "You must provide a AcknowledgeMessageAsHandled instance");

        return unitOfWorkFactory.withUnitOfWork(() -> newInterceptorChainForOperation(operation,
                                                                                      interceptors,
                                                                                      (interceptor, interceptorChain) -> interceptor.intercept(operation, interceptorChain),
                                                                                      () -> {
                                                                                          log.debug("Acknowledging-Message-As-Handled regarding Message with id '{}'", operation.queueEntryId);
                                                                                          var queueEntryId = operation.queueEntryId;
                                                                                          var rowsUpdated = unitOfWorkFactory.getRequiredUnitOfWork().handle().createUpdate(bind("DELETE FROM {:tableName} WHERE id = :id AND is_dead_letter_message = FALSE",
                                                                                                                                                                                 arg("tableName", sharedQueueTableName)))
                                                                                                                             .bind("id", operation.queueEntryId)
                                                                                                                             .execute();
                                                                                          if (rowsUpdated == 1) {
                                                                                              log.debug("Acknowledged message as handled and deleted it. Id: '{}'", queueEntryId);
                                                                                              return true;
                                                                                          } else if (getDeadLetterMessage(new GetDeadLetterMessage(operation.queueEntryId)).isPresent()) {
                                                                                              log.debug("Couldn't acknowledge message as it was marked as a Dead-Letter-Message during the message handling. Id: '{}'", queueEntryId);
                                                                                              return true;
                                                                                          } else {
                                                                                              log.error("Couldn't Acknowledge with id '{}' - it may already have been deleted", queueEntryId);
                                                                                              return false;
                                                                                          }
                                                                                      })
                .proceed());

    }

    @Override
    public final boolean deleteMessage(DeleteMessage operation) {
        requireNonNull(operation, "You must provide a DeleteMessage instance");

        return newInterceptorChainForOperation(operation,
                                               interceptors,
                                               (interceptor, interceptorChain) -> interceptor.intercept(operation, interceptorChain),
                                               () -> {
                                                   var rowsUpdated = unitOfWorkFactory.getRequiredUnitOfWork().handle().createUpdate(bind("DELETE FROM {:tableName} WHERE id = :id",
                                                                                                                                          arg("tableName", sharedQueueTableName)))
                                                                                      .bind("id", operation.queueEntryId)
                                                                                      .execute();
                                                   if (rowsUpdated == 1) {
                                                       log.debug("Deleted Message with id '{}'", operation.queueEntryId);
                                                       return true;
                                                   } else {
                                                       log.error("Couldn't Delete Message with id '{}' - it may already have been deleted", operation.queueEntryId);
                                                       return false;
                                                   }
                                               }).proceed();
    }

    //@Override
    public final Optional<QueuedMessage> getNextMessageReadyForDelivery_(GetNextMessageReadyForDelivery operation) {
        requireNonNull(operation, "You must specify a GetNextMessageReadyForDelivery instance");
        log.trace("[{}] Entered GetNextMessageReadyForDelivery", operation.queueName);

        return newInterceptorChainForOperation(operation,
                                               interceptors,
                                               (interceptor, interceptorChain) -> interceptor.intercept(operation, interceptorChain),
                                               () -> {
                                                   log.trace("[{}] Handling GetNextMessageReadyForDelivery: {}", operation.queueName, operation);
                                                   resetMessagesStuckBeingDelivered(operation.queueName);
                                                   var                now          = Instant.now();
                                                   Collection<String> excludedKeys = operation.getExcludeOrderedMessagesWithKey() != null ? operation.getExcludeOrderedMessagesWithKey() : List.of();

                                                   var sql = buildGetNextMessageReadyForDeliverySqlStatement(excludedKeys);
                                                   log.trace("[{}] Querying Postgresql: {}", operation.queueName, operation);
                                                   var query = unitOfWorkFactory.getRequiredUnitOfWork().handle().createQuery(sql)
                                                                                .bind("queueName", operation.queueName)
                                                                                .bind("now", now)
                                                                                .bind("limit", 1);
                                                   if (!excludedKeys.isEmpty()) {
                                                       query.bindList("excludedKeys", excludedKeys);
                                                   }
                                                   Optional<QueuedMessage> result;
                                                   try {
                                                       result = query
                                                               .map(queuedMessageMapper)
                                                               .findOne();
                                                   } catch (DurableQueueDeserializationException e) {
                                                       log.error("[{}] Marking Message as DeadLetterMessage due to DurableQueueDeserializationException while deserializing message with id '{}'", operation.queueName, e.queueEntryId.get(), e);
                                                       markAsDeadLetterMessage(e.queueEntryId.get(), e);
                                                       return Optional.<QueuedMessage>empty();
                                                   }
                                                   log.trace("[{}] Completed GetNextMessageReadyForDelivery: {}", operation.queueName, operation);
                                                   return result;
                                               }).proceed();

    }

    public String buildGetNextMessageReadyForDeliverySqlStatement(Collection<String> excludeOrderedMessagesWithKey) {
        var excludeKeysLimitSql = "";
        var excludedKeys        = excludeOrderedMessagesWithKey != null ? excludeOrderedMessagesWithKey : List.of();
        if (!excludedKeys.isEmpty()) {
            excludeKeysLimitSql = "        AND key NOT IN (<excludedKeys>)\n";
        }

        return bind("""
                    WITH queued_message_ready_for_delivery AS (
                        SELECT id FROM {:tableName} q1
                        WHERE
                            queue_name = :queueName AND
                            is_dead_letter_message = FALSE AND
                            is_being_delivered = FALSE AND
                            next_delivery_ts <= :now AND
                            NOT EXISTS (SELECT 1 FROM {:tableName} q2 WHERE q2.key = q1.key AND q2.queue_name = q1.queue_name AND q2.key_order < q1.key_order)
                                {:excludeKeys}
                        ORDER BY key_order ASC, next_delivery_ts ASC
                        LIMIT :limit
                        FOR UPDATE SKIP LOCKED
                    )
                            UPDATE {:tableName} queued_message SET
                                total_attempts = queued_message.total_attempts + 1,
                                next_delivery_ts = NULL,
                                is_being_delivered = TRUE,
                                delivery_ts = :now
                            FROM queued_message_ready_for_delivery
                            WHERE queued_message.id = queued_message_ready_for_delivery.id
                            AND queued_message.queue_name = :queueName
                            RETURNING
                                queued_message.id,
                                queued_message.queue_name,
                                queued_message.message_payload,
                                queued_message.message_payload_type,
                                queued_message.added_ts,
                                queued_message.next_delivery_ts,
                                queued_message.delivery_ts,
                                queued_message.last_delivery_error,
                                queued_message.total_attempts,
                                queued_message.redelivery_attempts,
                                queued_message.is_dead_letter_message,
                                queued_message.is_being_delivered,
                                queued_message.meta_data,
                                queued_message.delivery_mode,
                                queued_message.key,
                                queued_message.key_order
                    """,
                    arg("tableName", sharedQueueTableName),
                    arg("excludeKeys", excludeKeysLimitSql));

    }

    public Optional<QueuedMessage> getNextMessageReadyForDelivery(GetNextMessageReadyForDelivery operation) {
        if (useOrderedUnorderedQuery) {
            log.info("[{}] Using OrderedUnorderedQuery", operation.queueName);
            return getNextMessageReadyForDeliveryOrderedUnordered(operation);
        }
        return getNextMessageReadyForDelivery_(operation);
    }

    public Optional<QueuedMessage> getNextMessageReadyForDeliveryOrderedUnordered(GetNextMessageReadyForDelivery operation) {
        requireNonNull(operation, "You must specify a GetNextMessageReadyForDelivery instance");
        log.trace("[{}] Entered GetNextMessageReadyForDelivery", operation.queueName);

        return newInterceptorChainForOperation(operation, interceptors,
                                               (interceptor, chain) -> interceptor.intercept(operation, chain),
                                               () -> {
                                                   resetMessagesStuckBeingDelivered(operation.queueName);
                                                   var     now           = Instant.now();
                                                   var     excludes      = operation.getExcludeOrderedMessagesWithKey();
                                                   boolean hasExclusives = excludes != null && !excludes.isEmpty();

                                                   var orderedSql = buildOrderedSqlStatement(hasExclusives);

                                                   var unorderedSql = buildUnorderedSqlStatement();
                                                   try {
                                                       return unitOfWorkFactory.getRequiredUnitOfWork()
                                                                               .handle()
                                                                               .inTransaction(handle -> {
                                                                                   var qOrdered = handle.createQuery(orderedSql)
                                                                                                        .bind("queueName", operation.queueName)
                                                                                                        .bind("now", now)
                                                                                                        .bind("limit", 1);
                                                                                   if (hasExclusives) qOrdered.bindList("excludeKeys", excludes);

                                                                                   Optional<QueuedMessage> ordered = qOrdered
                                                                                           .map(queuedMessageMapper)
                                                                                           .findOne();
                                                                                   if (ordered.isPresent()) {
                                                                                       return ordered;
                                                                                   }

                                                                                   return handle.createQuery(unorderedSql)
                                                                                                .bind("queueName", operation.queueName)
                                                                                                .bind("now", now)
                                                                                                .bind("limit", 1)
                                                                                                .map(queuedMessageMapper)
                                                                                                .findOne();
                                                                               });
                                                   } catch (DurableQueueDeserializationException e) {
                                                       log.error("[{}] Marking Message as DeadLetterMessage due to DurableQueueDeserializationException while deserializing message with id '{}'", operation.queueName, e.queueEntryId.get(), e);
                                                       markAsDeadLetterMessage(e.queueEntryId.get(), e);
                                                       return Optional.<QueuedMessage>empty();
                                                   }
                                               })
                .proceed();
    }

    /**
     * Builds and returns an SQL statement that selects and updates rows
     * from a specific queue table that are ready for processing. The selected
     * rows are updated atomically to mark them as being delivered and update
     * the delivery timestamp. The SQL query also applies specific conditions
     * regarding the queue and message properties to determine eligible rows.
     *
     * @return A string representing the SQL statement to process queue messages
     * in an unordered manner based on the specified conditions.
     */
    public String buildUnorderedSqlStatement() {
        return bind("""
                      WITH cte_unordered AS (
                        SELECT id
                        FROM {:tableName} q
                        WHERE
                             queue_name = :queueName
                          AND is_dead_letter_message = FALSE
                          AND is_being_delivered     = FALSE
                          AND next_delivery_ts <= :now
                          AND key IS NULL
                        ORDER BY next_delivery_ts
                        LIMIT :limit
                        FOR UPDATE SKIP LOCKED
                      )
                      UPDATE {:tableName} q
                      SET
                        total_attempts       = q.total_attempts + 1,
                        next_delivery_ts     = NULL,
                        is_being_delivered   = TRUE,
                        delivery_ts          = :now
                      FROM cte_unordered u
                      WHERE q.id = u.id
                        AND q.queue_name = :queueName
                      RETURNING q.*;
                    """, arg("tableName", sharedQueueTableName));
    }

    /**
     * Constructs an SQL statement for ordering and updating a message queue.
     * The statement uses common table expressions (CTE) to first select eligible
     * messages based on specific conditions, and then updates and returns those messages.
     *
     * @param hasExclusiveKeys a boolean flag indicating whether exclusive keys
     *                         should be excluded from the query. If true, the SQL
     *                         will include an additional condition to exclude keys
     *                         from the provided exclusion list.
     * @return the constructed SQL statement as a String. The statement includes
     * logic for selecting, ordering, and updating messages in a queue table.
     */
    public String buildOrderedSqlStatement(boolean hasExclusiveKeys) {
        var orderedSql = new StringBuilder();
        orderedSql.append("""
                          WITH cte_ordered AS (
                                     SELECT id
                                     FROM %s q
                                     WHERE
                                          queue_name             = :queueName
                                      AND is_dead_letter_message = FALSE
                                      AND is_being_delivered     = FALSE
                                      AND next_delivery_ts      <= :now
                          
                                      AND key IS NOT NULL
                          
                                      -- full per-key barrier:
                                      AND NOT EXISTS (
                                        SELECT 1
                                        FROM %1$s q2
                                        WHERE q2.key        = q.key
                                          AND q2.queue_name = q.queue_name
                                          AND q2.key_order  < q.key_order
                                      )
                          """.formatted(sharedQueueTableName));
        if (hasExclusiveKeys) {
            orderedSql.append("\n    AND key NOT IN (<excludeKeys>)");
        }
        orderedSql.append("""
                           ORDER BY key_order, next_delivery_ts
                                              LIMIT :limit
                                              FOR UPDATE SKIP LOCKED
                                            )
                                            UPDATE %1$s q
                                            SET
                                              total_attempts       = q.total_attempts + 1,
                                              next_delivery_ts     = NULL,
                                              is_being_delivered   = TRUE,
                                              delivery_ts          = :now
                                            FROM cte_ordered o
                                            WHERE q.id = o.id
                                              AND q.queue_name = :queueName
                                            RETURNING q.*;
                          """.formatted(sharedQueueTableName));
        return orderedSql.toString();
    }


    /**
     * This operation will scan for messages that has been marked as {@link QueuedMessage#isBeingDelivered()} for longer
     * than {@link #messageHandlingTimeoutMs}<br>
     * All messages found will have {@link QueuedMessage#isBeingDelivered()} and {@link QueuedMessage#getDeliveryTimestamp()}
     * reset<br>
     * Only relevant for when using {@link TransactionalMode#SingleOperationTransaction}
     *
     * @param queueName the queue for which we're looking for messages stuck being marked as {@link QueuedMessage#isBeingDelivered()}
     */
    protected final void resetMessagesStuckBeingDelivered(QueueName queueName) {
        // Reset stuck messages
        if (transactionalMode == TransactionalMode.SingleOperationTransaction) {
            var now                            = Instant.now();
            var lastStuckMessageResetTimestamp = lastResetStuckMessagesCheckTimestamps.get(queueName);
            if (lastStuckMessageResetTimestamp == null || Duration.between(now, lastStuckMessageResetTimestamp).abs().toMillis() > messageHandlingTimeoutMs) {
                if (log.isDebugEnabled()) {
                    log.debug("[{}] Looking for messages stuck marked as isBeingDelivered. Last check was performed: {}", queueName, lastStuckMessageResetTimestamp);
                }

                var numberOfChanges = unitOfWorkFactory.getRequiredUnitOfWork().handle().createUpdate(bind("UPDATE {:tableName} SET\n" +
                                                                                                                   "     is_being_delivered = FALSE,\n" +
                                                                                                                   "     delivery_ts = NULL,\n" +
                                                                                                                   "     redelivery_attempts = redelivery_attempts + 1,\n" +
                                                                                                                   "     next_delivery_ts = :now,\n" +
                                                                                                                   "     last_delivery_error = :error\n" +
                                                                                                                   " WHERE is_being_delivered = TRUE\n" +
                                                                                                                   " AND delivery_ts <= :threshold\n",
                                                                                                           arg("tableName", sharedQueueTableName)))
                                                       .bind("threshold", now.minusMillis(messageHandlingTimeoutMs))
                                                       .bind("error", "Handler Processing of the Message was determined to have Timed Out")
                                                       .bind("now", now)
                                                       .execute();
                if (numberOfChanges > 0) {
                    log.debug("[{}] Reset {} messages stuck marked as isBeingDelivered", queueName, numberOfChanges);
                } else {
                    log.debug("[{}] Didn't find any messages being stuck marked as isBeingDelivered", queueName);
                }
                lastResetStuckMessagesCheckTimestamps.put(queueName, now);
            }
        }
    }

    @Override
    public final boolean hasMessagesQueuedFor(QueueName queueName) {
        return getTotalMessagesQueuedFor(queueName) > 0;
    }


    @Override
    public final boolean hasOrderedMessageQueuedForKey(QueueName queueName, String key) {
        requireNonNull(queueName, "No queueName provided");
        requireNonNull(key, "No key provided");
        return unitOfWorkFactory.withUnitOfWork(handleAwareUnitOfWork -> handleAwareUnitOfWork.handle().createQuery(bind("SELECT count(*) FROM {:tableName} \n" +
                                                                                                                                 " WHERE \n" +
                                                                                                                                 "    queue_name = :queueName AND\n" +
                                                                                                                                 "    key = :key AND\n" +
                                                                                                                                 "    delivery_mode = 'IN_ORDER'",
                                                                                                                         arg("tableName", sharedQueueTableName)))
                                                                                              .bind("queueName", queueName)
                                                                                              .bind("key", key)
                                                                                              .mapTo(Long.class)
                                                                                              .one()) > 0;
    }

    @Override
    public final long getTotalMessagesQueuedFor(GetTotalMessagesQueuedFor operation) {
        requireNonNull(operation, "You must specify a GetTotalMessagesQueuedFor instance");
        return newInterceptorChainForOperation(operation,
                                               interceptors,
                                               (interceptor, interceptorChain) -> interceptor.intercept(operation, interceptorChain),
                                               () -> unitOfWorkFactory.withUnitOfWork(handleAwareUnitOfWork -> handleAwareUnitOfWork.handle().createQuery(bind("SELECT count(*) FROM {:tableName} \n" +
                                                                                                                                                                       " WHERE \n" +
                                                                                                                                                                       "    queue_name = :queueName AND\n" +
                                                                                                                                                                       "    is_dead_letter_message = FALSE",
                                                                                                                                                               arg("tableName", sharedQueueTableName)))
                                                                                                                                    .bind("queueName", operation.queueName)
                                                                                                                                    .mapTo(Long.class)
                                                                                                                                    .one()))
                .proceed();
    }

    @Override
    public QueuedMessageCounts getQueuedMessageCountsFor(GetQueuedMessageCountsFor operation) {
        requireNonNull(operation, "You must specify a GetTotalMessagesQueuedFor instance");
        return newInterceptorChainForOperation(operation,
                                               interceptors,
                                               (interceptor, interceptorChain) -> interceptor.intercept(operation, interceptorChain),
                                               () -> unitOfWorkFactory.withUnitOfWork(handleAwareUnitOfWork -> handleAwareUnitOfWork.handle().createQuery(bind("SELECT \n" +
                                                                                                                                                                       "    COUNT(*) FILTER (WHERE is_dead_letter_message = FALSE) AS regular_count,\n" +
                                                                                                                                                                       "    COUNT(*) FILTER (WHERE is_dead_letter_message = TRUE) AS dead_letter_count\n" +
                                                                                                                                                                       "FROM {:tableName} \n" +
                                                                                                                                                                       " WHERE \n" +
                                                                                                                                                                       "    queue_name = :queueName",
                                                                                                                                                               arg("tableName", sharedQueueTableName)))
                                                                                                                                    .bind("queueName", operation.queueName)
                                                                                                                                    .map((rs, ctx) -> new QueuedMessageCounts(operation.queueName,
                                                                                                                                                                              rs.getLong("regular_count"),
                                                                                                                                                                              rs.getLong("dead_letter_count")))
                                                                                                                                    .one()))
                .proceed();
    }

    @Override
    public final long getTotalDeadLetterMessagesQueuedFor(GetTotalDeadLetterMessagesQueuedFor operation) {
        requireNonNull(operation, "You must specify a GetTotalDeadLetterMessagesQueuedFor instance");
        return newInterceptorChainForOperation(operation,
                                               interceptors,
                                               (interceptor, interceptorChain) -> interceptor.intercept(operation, interceptorChain),
                                               () -> unitOfWorkFactory.withUnitOfWork(handleAwareUnitOfWork -> handleAwareUnitOfWork.handle().createQuery(bind("SELECT count(*) FROM {:tableName} \n" +
                                                                                                                                                                       " WHERE \n" +
                                                                                                                                                                       "    queue_name = :queueName AND\n" +
                                                                                                                                                                       "    is_dead_letter_message = TRUE",
                                                                                                                                                               arg("tableName", sharedQueueTableName)))
                                                                                                                                    .bind("queueName", operation.queueName)
                                                                                                                                    .mapTo(Long.class)
                                                                                                                                    .one()))
                .proceed();
    }

    @Override
    public final int purgeQueue(PurgeQueue operation) {
        requireNonNull(operation, "You must specify a PurgeQueue instance");
        return newInterceptorChainForOperation(operation,
                                               interceptors,
                                               (interceptor, interceptorChain) -> interceptor.intercept(operation, interceptorChain),
                                               () -> unitOfWorkFactory.withUnitOfWork(handleAwareUnitOfWork -> handleAwareUnitOfWork.handle().createUpdate(bind("DELETE FROM {:tableName} WHERE queue_name = :queueName",
                                                                                                                                                                arg("tableName", sharedQueueTableName)))
                                                                                                                                    .bind("queueName", operation.queueName)
                                                                                                                                    .execute()))
                .proceed();
    }

    @Override
    public final List<NextQueuedMessage> queryForMessagesSoonReadyForDelivery(QueueName queueName, Instant withNextDeliveryTimestampAfter, int maxNumberOfMessagesToReturn) {
        requireNonNull(queueName, "No queueName provided");
        requireNonNull(withNextDeliveryTimestampAfter, "No withNextDeliveryTimestampAfter provided");


        return unitOfWorkFactory.withUnitOfWork(handleAwareUnitOfWork -> handleAwareUnitOfWork.handle().createQuery(bind("SELECT id, added_ts, next_delivery_ts FROM {:tableName} \n" +
                                                                                                                                 " WHERE queue_name = :queueName\n" +
                                                                                                                                 " AND is_dead_letter_message = FALSE\n" +
                                                                                                                                 " AND is_being_delivered = FALSE\n" +
                                                                                                                                 " AND next_delivery_ts > :now\n" +
                                                                                                                                 " ORDER BY next_delivery_ts ASC\n" +
                                                                                                                                 " LIMIT :pageSize",
                                                                                                                         arg("tableName", sharedQueueTableName)))
                                                                                              .bind("queueName", requireNonNull(queueName, "No QueueName provided"))
                                                                                              .bind("now", withNextDeliveryTimestampAfter)
                                                                                              .bind("pageSize", maxNumberOfMessagesToReturn)
                                                                                              .map((rs, ctx) -> new NextQueuedMessage(QueueEntryId.of(rs.getString("id")),
                                                                                                                                      queueName,
                                                                                                                                      rs.getObject("added_ts", OffsetDateTime.class).toInstant(),
                                                                                                                                      rs.getObject("next_delivery_ts", OffsetDateTime.class).toInstant()))
                                                                                              .list());
    }

    @Override
    public final List<QueuedMessage> getQueuedMessages(GetQueuedMessages operation) {
        requireNonNull(operation, "You must specify a GetQueuedMessages instance");
        return newInterceptorChainForOperation(operation,
                                               interceptors,
                                               (interceptor, interceptorChain) -> interceptor.intercept(operation, interceptorChain),
                                               () -> queryQueuedMessages(operation.queueName, operation.getQueueingSortOrder(), IncludeMessages.QUEUED_MESSAGES, operation.getStartIndex(), operation.getPageSize()))
                .proceed();
    }

    @Override
    public final List<QueuedMessage> getDeadLetterMessages(GetDeadLetterMessages operation) {
        requireNonNull(operation, "You must specify a GetDeadLetterMessages instance");
        return newInterceptorChainForOperation(operation,
                                               interceptors,
                                               (interceptor, interceptorChain) -> interceptor.intercept(operation, interceptorChain),
                                               () -> queryQueuedMessages(operation.queueName, operation.getQueueingSortOrder(), IncludeMessages.DEAD_LETTER_MESSAGES, operation.getStartIndex(), operation.getPageSize()))
                .proceed();
    }


    protected enum IncludeMessages {
        ALL, DEAD_LETTER_MESSAGES, QUEUED_MESSAGES
    }

    protected final List<QueuedMessage> queryQueuedMessages(QueueName queueName, QueueingSortOrder queueingSortOrder, IncludeMessages includeMessages, long startIndex, long pageSize) {
        requireNonNull(queueName, "No queueName provided");
        requireNonNull(queueingSortOrder, "No queueingOrder provided");
        requireNonNull(includeMessages, "No includeMessages provided");

        Supplier<String> resolveIncludeMessagesSql = () -> {
            switch (includeMessages) {
                case ALL:
                    return "";
                case DEAD_LETTER_MESSAGES:
                    return "AND is_dead_letter_message = TRUE\n";
                case QUEUED_MESSAGES:
                    return "AND is_dead_letter_message = FALSE\n";
                default:
                    throw new IllegalArgumentException("Unsupported IncludeMessages value: " + includeMessages);
            }
        };

        return unitOfWorkFactory.withUnitOfWork(handleAwareUnitOfWork -> handleAwareUnitOfWork.handle().createQuery(bind("SELECT * FROM {:tableName} \n" +
                                                                                                                                 " WHERE queue_name = :queueName\n" +
                                                                                                                                 "{:includeMessages}" +
                                                                                                                                 " LIMIT :pageSize \n" +
                                                                                                                                 " OFFSET :offset",
                                                                                                                         arg("tableName", sharedQueueTableName),
                                                                                                                         arg("includeMessages", resolveIncludeMessagesSql.get())))
                                                                                              .bind("queueName", requireNonNull(queueName, "No QueueName provided"))
                                                                                              .bind("offset", startIndex)
                                                                                              .bind("pageSize", pageSize)
                                                                                              .map(queuedMessageMapper)
                                                                                              .list());
    }

    @Override
    public final DurableQueues addInterceptor(DurableQueuesInterceptor interceptor) {
        requireNonNull(interceptor, "No interceptor provided");
        log.info("Adding interceptor: {}", interceptor);
        interceptor.setDurableQueues(this);
        interceptors.add(interceptor);
        sortInterceptorsByOrder(interceptors);
        return this;
    }

    @Override
    public final DurableQueues removeInterceptor(DurableQueuesInterceptor interceptor) {
        requireNonNull(interceptor, "No interceptor provided");
        log.info("Removing interceptor: {}", interceptor);
        interceptors.remove(interceptor);
        sortInterceptorsByOrder(interceptors);
        return this;
    }

    @Override
    public final Optional<QueueName> getQueueNameFor(QueueEntryId queueEntryId) {
        return unitOfWorkFactory.withUnitOfWork(handleAwareUnitOfWork -> handleAwareUnitOfWork.handle()
                                                                                              .createQuery(bind("SELECT queue_name FROM {:tableName} WHERE \n" +
                                                                                                                        " id = :id",
                                                                                                                arg("tableName", sharedQueueTableName)))
                                                                                              .bind("id", requireNonNull(queueEntryId, "No queueEntryId provided"))
                                                                                              .mapTo(QueueName.class)
                                                                                              .findOne());
    }

    @Override
    public final Optional<QueuedMessage> getDeadLetterMessage(GetDeadLetterMessage operation) {
        requireNonNull(operation, "You must specify a GetDeadLetterMessage instance");
        return newInterceptorChainForOperation(operation,
                                               interceptors,
                                               (interceptor, interceptorChain) -> interceptor.intercept(operation, interceptorChain),
                                               () -> getQueuedMessage(operation.queueEntryId, true))
                .proceed();
    }

    /**
     * Implementation of the batch message fetching capability to optimize database queries
     * by fetching messages across multiple queues in a single operation.
     *
     * @param queueNames                   the queue names to fetch messages for
     * @param excludeKeysPerQueue          map of queue name to set of keys to exclude (for ordered messages)
     * @param availableWorkerSlotsPerQueue map of queue name to number of available worker slots
     * @return list of queued messages ready for delivery
     */
    @Override
    public List<QueuedMessage> fetchNextBatchOfMessages(Collection<QueueName> queueNames,
                                                        Map<QueueName, Set<String>> excludeKeysPerQueue,
                                                        Map<QueueName, Integer> availableWorkerSlotsPerQueue) {
        requireNonNull(queueNames, "No queueNames provided");
        requireNonNull(excludeKeysPerQueue, "No excludeKeysPerQueue provided");
        requireNonNull(availableWorkerSlotsPerQueue, "No availableWorkerSlotsPerQueue provided");
        if (useOrderedUnorderedQuery) {
            return fetchNextBatchOfMessagesOrderedUnordered(queueNames, excludeKeysPerQueue, availableWorkerSlotsPerQueue);
        }
        return fetchNextBatchOfMessages_(queueNames, excludeKeysPerQueue, availableWorkerSlotsPerQueue);
    }

    /**
     * Implementation of the batch message fetching capability to optimize database queries
     * by fetching messages across multiple queues in a single operation.
     *
     * @param queueNames                   the queue names to fetch messages for
     * @param excludeKeysPerQueue          map of queue name to set of keys to exclude (for ordered messages)
     * @param availableWorkerSlotsPerQueue map of queue name to number of available worker slots
     * @return list of queued messages ready for delivery
     */
    public List<QueuedMessage> fetchNextBatchOfMessages_(Collection<QueueName> queueNames,
                                                         Map<QueueName, Set<String>> excludeKeysPerQueue,
                                                         Map<QueueName, Integer> availableWorkerSlotsPerQueue) {
        log.trace("Fetching batch of messages for queues: {}", queueNames);
        if (queueNames.isEmpty()) {
            return Collections.emptyList();
        }

        try {
            return unitOfWorkFactory.withUnitOfWork(handleAwareUnitOfWork -> {
                resetMessagesStuckBeingDeliveredAcrossMultipleQueues(queueNames);

                var now         = Instant.now();
                var allMessages = new ArrayList<QueuedMessage>();

                // Build separate queries for each queue - using the same pattern as getNextMessageReadyForDelivery
                for (var queueName : queueNames) {
                    if (!availableWorkerSlotsPerQueue.containsKey(queueName) ||
                            availableWorkerSlotsPerQueue.get(queueName) <= 0) {
                        log.trace("[{}] Skipping queue as it has no available worker slots", queueName);
                        continue;
                    }

                    var durableQueueConsumer = durableQueueConsumers.get(queueName);
                    if (durableQueueConsumer == null) {
                        log.trace("[{}] Skipping queue as it has no consumer", queueName);
                        continue;
                    }
                    var queuePollingOptimizer = durableQueueConsumer.getQueuePollingOptimizer();
                    if (queuePollingOptimizer.shouldSkipPolling()) {
                        log.trace("[{}] skipping centralized polling", queueName);
                        continue;
                    }

                    var limit        = availableWorkerSlotsPerQueue.get(queueName);
                    var excludedKeys = excludeKeysPerQueue.getOrDefault(queueName, Collections.emptySet());

                    var sql = buildGetNextMessageReadyForDeliverySqlStatement(excludedKeys);
                    // Create and execute the query
                    var query = handleAwareUnitOfWork.handle().createQuery(sql)
                                                     .bind("queueName", queueName)
                                                     .bind("now", now)
                                                     .bind("limit", limit);

                    if (!excludedKeys.isEmpty()) {
                        query.bindList("excludedKeys", new ArrayList<>(excludedKeys));
                    }

                    try {
                        // Fetch messages for this queue and add to results
                        var messagesForQueue = query.map(queuedMessageMapper).list();
                        log.debug("[{}] Batch fetched {} messages with {} slots available",
                                  queueName,
                                  messagesForQueue.size(),
                                  limit);

                        if (messagesForQueue.isEmpty()) {
                            queuePollingOptimizer.queuePollingReturnedNoMessages();
                            log.trace("[{}] No messages fetched for this queue", queueName);
                        } else {
                            queuePollingOptimizer.queuePollingReturnedMessages(messagesForQueue);
                            log.trace("[{}] Fetched {} messages for this queue", queueName, messagesForQueue.size());
                        }

                        allMessages.addAll(messagesForQueue);
                    } catch (DurableQueueDeserializationException e) {
                        log.error("[{}] Marking Message as DeadLetterMessage due to DurableQueueDeserializationException while deserializing message with id '{}'", queueName, e.queueEntryId.get(), e);
                        markAsDeadLetterMessage(e.queueEntryId.get(), e);
                    }
                }

                log.debug("Batch fetched {} messages for {} queues: {}",
                          allMessages.size(),
                          queueNames.size(),
                          queueNames);

                return allMessages;
            });
        } catch (Exception e) {
            if (IOExceptionUtil.isIOException(e)) {
                log.debug("Error in fetchNextBatchOfMessages: {}", e.getMessage(), e);
            } else {
                log.error("Error in fetchNextBatchOfMessages: {}", e.getMessage(), e);
            }
            return Collections.emptyList();
        }
    }

    public List<QueuedMessage> fetchNextBatchOfMessagesOrderedUnordered(Collection<QueueName> queueNames,
                                                                        Map<QueueName, Set<String>> excludeKeysPerQueue,
                                                                        Map<QueueName, Integer> availableWorkerSlotsPerQueue) {
        log.trace("Fetching batch of messages for queues: {}", queueNames);
        if (queueNames.isEmpty()) {
            return Collections.emptyList();
        }

        try {
            return unitOfWorkFactory.withUnitOfWork(uow -> {
                resetMessagesStuckBeingDeliveredAcrossMultipleQueues(queueNames);

                var now         = Instant.now();
                var allMessages = new ArrayList<QueuedMessage>();

                // Build separate queries for each queue - using the same pattern as getNextMessageReadyForDelivery
                for (var queueName : queueNames) {
                    if (!availableWorkerSlotsPerQueue.containsKey(queueName) ||
                            availableWorkerSlotsPerQueue.get(queueName) <= 0) {
                        log.trace("[{}] Skipping queue as it has no available worker slots", queueName);
                        continue;
                    }

                    var durableQueueConsumer = durableQueueConsumers.get(queueName);
                    if (durableQueueConsumer == null) {
                        log.trace("[{}] Skipping queue as it has no consumer", queueName);
                        continue;
                    }
                    var queuePollingOptimizer = durableQueueConsumer.getQueuePollingOptimizer();
                    if (queuePollingOptimizer.shouldSkipPolling()) {
                        log.trace("[{}] skipping centralized polling", queueName);
                        continue;
                    }

                    var     limit         = availableWorkerSlotsPerQueue.get(queueName);
                    var     excludedKeys  = excludeKeysPerQueue.getOrDefault(queueName, Collections.emptySet());
                    boolean hasExclusives = !excludedKeys.isEmpty();

                    try {
                        var orderedSql = buildOrderedSqlStatement(hasExclusives);
                        var orderedQuery = uow.handle().createQuery(orderedSql)
                                              .bind("queueName", queueName)
                                              .bind("now", now)
                                              .bind("limit", limit);
                        if (hasExclusives) orderedQuery.bindList("excludeKeys", excludedKeys);

                        var messagesForQueue = orderedQuery.map(queuedMessageMapper).list();
                        if (messagesForQueue.isEmpty()) { // TODO: maybe we should do both?
                            var unorderedSql = buildUnorderedSqlStatement();
                            var unorderedQuery = uow.handle().createQuery(unorderedSql)
                                                    .bind("queueName", queueName)
                                                    .bind("now", now)
                                                    .bind("limit", limit);
                            messagesForQueue = unorderedQuery.map(queuedMessageMapper).list();
                        }
                        log.debug("[{}] Batch fetched {} messages with {} slots available",
                                  queueName,
                                  messagesForQueue.size(),
                                  limit);

                        if (messagesForQueue.isEmpty()) {
                            queuePollingOptimizer.queuePollingReturnedNoMessages();
                            log.trace("[{}] No messages fetched for this queue", queueName);
                        } else {
                            queuePollingOptimizer.queuePollingReturnedMessages(messagesForQueue);
                            log.trace("[{}] Fetched {} messages for this queue", queueName, messagesForQueue.size());
                        }

                        allMessages.addAll(messagesForQueue);
                    } catch (DurableQueueDeserializationException e) {
                        log.error("[{}] Marking Message as DeadLetterMessage due to DurableQueueDeserializationException while deserializing message with id '{}'", queueName, e.queueEntryId.get(), e);
                        markAsDeadLetterMessage(e.queueEntryId.get(), e);
                    }
                }

                return allMessages;
            });
        } catch (Exception e) {
            if (IOExceptionUtil.isIOException(e)) {
                log.debug("Error in fetchNextBatchOfMessages: {}", e.getMessage(), e);
            } else {
                log.error("Error in fetchNextBatchOfMessages: {}", e.getMessage(), e);
            }
            return Collections.emptyList();
        }
    }

    /**
     * Fetches the next batch of messages across multiple queues in one round-trip,
     * applying per-queue backoff/skip logic and updating each queue’s optimizer.
     */
    public List<QueuedMessage> fetchNextBatchOfMessagesBatched(Collection<QueueName> queueNames,
                                                               Map<QueueName, Set<String>> excludeKeysPerQueue,
                                                               Map<QueueName, Integer> availableWorkerSlotsPerQueue) {

        log.trace("Fetching batch of messages for queues: {}", queueNames);

        // 1) Filter out queues with no slots or that should skip polling
        List<QueueName> activeQueues = queueNames.stream()
                                                 .filter(queueName -> availableWorkerSlotsPerQueue.getOrDefault(queueName, 0) > 0)
                                                 .filter(queueName -> {
                                                     var durableQueueConsumer = durableQueueConsumers.get(queueName);
                                                     if (durableQueueConsumer == null) {
                                                         log.trace("[{}] Skipping queue as it has no consumer", queueName);
                                                         return false;
                                                     }
                                                     var     queuePollingOptimizer = durableQueueConsumer.getQueuePollingOptimizer();
                                                     boolean skip                  = queuePollingOptimizer.shouldSkipPolling();
                                                     if (skip) log.trace("[{}] skipping due to backoff", queueName);
                                                     return !skip;
                                                 })
                                                 .toList();

        if (activeQueues.isEmpty()) {
            return Collections.emptyList();
        }

        try {
            return unitOfWorkFactory.withUnitOfWork(uow -> {
                resetMessagesStuckBeingDeliveredAcrossMultipleQueues(activeQueues);

                Instant now = Instant.now();

                String sql = buildBatchedSqlStatement(excludeKeysPerQueue, availableWorkerSlotsPerQueue, activeQueues);

                List<QueuedMessage> messages = uow.handle()
                                                  .createQuery(sql)
                                                  .bind("now", now)
                                                  .map(queuedMessageMapper)
                                                  .list();

                Map<QueueName, List<QueuedMessage>> byQueue = messages.stream()
                                                                      .collect(Collectors.groupingBy(QueuedMessage::getQueueName));

                for (var queueName : activeQueues) {
                    var durableQueueConsumer = durableQueueConsumers.get(queueName);
                    if (durableQueueConsumer == null) {
                        log.trace("[{}] Skipping queue as it has no consumer", queueName);
                        continue;
                    }
                    var                 queuePollingOptimizer = durableQueueConsumer.getQueuePollingOptimizer();
                    List<QueuedMessage> messagesForQueue      = byQueue.getOrDefault(queueName, Collections.emptyList());
                    if (messagesForQueue.isEmpty()) {
                        queuePollingOptimizer.queuePollingReturnedNoMessages();
                    } else {
                        queuePollingOptimizer.queuePollingReturnedMessages(messagesForQueue);
                    }
                }

                log.debug("Batch fetched {} messages across {} queues: {}",
                          messages.size(),
                          activeQueues.size(),
                          byQueue.entrySet().stream()
                                 .collect(Collectors.toMap(Map.Entry::getKey, e -> e.getValue().size())));

                return messages;
            });
        } catch (Exception e) {
            if (IOExceptionUtil.isIOException(e)) {
                log.debug("Error in fetchNextBatchOfMessages: {}", e.getMessage(), e);
            } else {
                log.error("Error in fetchNextBatchOfMessages: {}", e.getMessage(), e);
            }
            return Collections.emptyList();
        }
    }

    public String buildBatchedSqlStatement(Map<QueueName, Set<String>> excludeKeysPerQueue, Map<QueueName, Integer> availableWorkerSlotsPerQueue, List<QueueName> activeQueues) {
        StringBuilder vals = new StringBuilder();
        for (int i = 0; i < activeQueues.size(); i++) {
            QueueName   q        = activeQueues.get(i);
            int         slots    = availableWorkerSlotsPerQueue.get(q);
            Set<String> excludes = excludeKeysPerQueue.getOrDefault(q, Collections.emptySet());

            // build SQL array literal of excluded keys
            String arrayLiteral = excludes.isEmpty()
                                  ? "ARRAY[]::text[]"
                                  : "ARRAY[" +
                                          excludes.stream()
                                                  .map(k -> "'" + k.replace("'", "''") + "'")
                                                  .collect(Collectors.joining(","))
                                          + "]::text[]";

            if (i > 0) vals.append(",\n    ");
            vals.append("('")
                .append(q.toString()).append("', ")
                .append(slots).append(", ")
                .append(arrayLiteral)
                .append(")");
        }

        return bind("""
                             WITH queue_config(queue_name, slots, exclude_keys) AS (
                               VALUES {:values}
                           ),
                           -- 2) Numbered ordered candidates
                               ordered_rn AS (
                                 SELECT
                                   q.id,
                                   q.queue_name,
                                   ROW_NUMBER() OVER (
                                     PARTITION BY q.queue_name
                                     ORDER BY q.key_order, q.next_delivery_ts
                                   ) AS rn
                                 FROM durable_queues q
                                 JOIN queue_config cfg USING(queue_name)
                                 WHERE
                                      q.is_dead_letter_message = FALSE
                                  AND q.is_being_delivered     = FALSE
                                  AND q.next_delivery_ts      <= :now
                                  AND q.key IS NOT NULL
                                  AND NOT (q.key = ANY(cfg.exclude_keys))
                                  AND NOT EXISTS (
                                    SELECT 1
                                    FROM durable_queues q2
                                    WHERE q2.queue_name = q.queue_name
                                      AND q2.key        = q.key
                                      AND q2.key_order  < q.key_order
                                  )
                               ),
        
                               -- 3) Numbered unordered candidates
                               unordered_rn AS (
                                 SELECT
                                   q.id,
                                   q.queue_name,
                                   ROW_NUMBER() OVER (
                                     PARTITION BY q.queue_name
                                     ORDER BY q.next_delivery_ts
                                   ) AS rn
                                 FROM durable_queues q
                                 JOIN queue_config cfg USING(queue_name)
                                 WHERE
                                      q.is_dead_letter_message = FALSE
                                  AND q.is_being_delivered     = FALSE
                                  AND q.next_delivery_ts      <= :now
                                  AND q.key IS NULL
                                  AND NOT (q.key = ANY(cfg.exclude_keys))
                               ),
        
                               -- 4) Pick up to cfg.slots from each
                               ordered_pick AS (
                                 SELECT orr.id
                                 FROM ordered_rn orr
                                 JOIN queue_config cfg
                                   ON orr.queue_name = cfg.queue_name
                                 WHERE orr.rn <= cfg.slots
                               ),
                               unordered_pick AS (
                                 SELECT unr.id
                                 FROM unordered_rn unr
                                 JOIN queue_config cfg
                                   ON unr.queue_name = cfg.queue_name
                                 WHERE unr.rn <= cfg.slots
                               ),
        
                               -- 5) Union them *without locking*
                               candidates AS (
                                 SELECT id FROM ordered_pick
                                 UNION ALL
                                 SELECT id FROM unordered_pick
                               ),
        
                               -- 6) Now lock exactly those durable_queues rows
                               locked AS (
                                 SELECT q.id
                                 FROM durable_queues q
                                 JOIN candidates c
                                   ON q.id = c.id
                                 FOR UPDATE SKIP LOCKED
                               )
        
                             -- 7) Finally, update & return the locked rows
                             UPDATE durable_queues dq
                             SET
                               total_attempts     = dq.total_attempts + 1,
                               next_delivery_ts   = NULL,
                               is_being_delivered = TRUE,
                               delivery_ts        = :now
                             FROM locked l
                             WHERE dq.id = l.id
                            RETURNING dq.*;
                          """, arg("values", vals.toString()), arg("tableName", sharedQueueTableName)
                   );
    }

    /**
     * Reset stuck messages that are marked as being delivered but haven't been acknowledged
     * across multiple queues at once
     *
     * @param queueNames the queue names to check for stuck messages
     */
    private void resetMessagesStuckBeingDeliveredAcrossMultipleQueues(Collection<QueueName> queueNames) {
        requireNonNull(queueNames, "No queueNames provided");
        if (transactionalMode != TransactionalMode.SingleOperationTransaction || queueNames.isEmpty()) {
            return;
        }

        log.trace("resetMultipleQueuesStuckBeingDelivered called for queues: {}", queueNames);
        var now = Instant.now();
        var queuesToReset = queueNames.stream()
                                      .filter(queueName -> {
                                          var lastReset = lastResetStuckMessagesCheckTimestamps.get(queueName);
                                          return lastReset == null ||
                                                  Duration.between(now, lastReset).abs().toMillis() > messageHandlingTimeoutMs;
                                      })
                                      .collect(Collectors.toList());

        if (queuesToReset.isEmpty()) {
            log.trace("No stuck messages to reset across multiple queues: {}", queueNames);
            return;
        }

        log.debug("Looking for messages stuck marked as isBeingDelivered across queues: {}", queuesToReset);

        var queueNamesForQuery = queuesToReset.stream()
                                              .map(QueueName::toString)
                                              .toList();

        var numberOfChanges = unitOfWorkFactory.getRequiredUnitOfWork().handle().createUpdate(bind(
                                                       "UPDATE {:tableName} SET\n" +
                                                               "     is_being_delivered = FALSE,\n" +
                                                               "     delivery_ts = NULL,\n" +
                                                               "     redelivery_attempts = redelivery_attempts + 1,\n" +
                                                               "     next_delivery_ts = :now,\n" +
                                                               "     last_delivery_error = :error\n" +
                                                               " WHERE is_being_delivered = TRUE\n" +
                                                               " AND delivery_ts <= :threshold\n" +
                                                               " AND queue_name IN (<queueNames>)",
                                                       arg("tableName", sharedQueueTableName)))
                                               .bind("threshold", now.minusMillis(messageHandlingTimeoutMs))
                                               .bind("error", "Handler Processing of the Message was determined to have Timed Out")
                                               .bind("now", now)
                                               .bindList("queueNames", queueNamesForQuery)
                                               .execute();

        if (numberOfChanges > 0) {
            log.debug("Reset {} messages stuck marked as isBeingDelivered across queues: {}",
                      numberOfChanges,
                      queuesToReset);
        } else {
            log.debug("No stuck messages found across queues: {}", queuesToReset);
        }

        // Update timestamps for all queues we checked
        queuesToReset.forEach(queueName -> lastResetStuckMessagesCheckTimestamps.put(queueName, now));
    }

    @Override
    public final Optional<QueuedMessage> getQueuedMessage(GetQueuedMessage operation) {
        requireNonNull(operation, "You must specify a GetQueuedMessage instance");
        return newInterceptorChainForOperation(operation,
                                               interceptors,
                                               (interceptor, interceptorChain) -> interceptor.intercept(operation, interceptorChain),
                                               () -> getQueuedMessage(operation.queueEntryId, false))
                .proceed();
    }

    private Optional<QueuedMessage> getQueuedMessage(QueueEntryId queueEntryId, boolean isDeadLetterMessage) {
        return unitOfWorkFactory.withUnitOfWork(handleAwareUnitOfWork -> handleAwareUnitOfWork.handle().createQuery(bind("SELECT * FROM {:tableName} WHERE \n" +
                                                                                                                                 " id = :id AND\n" +
                                                                                                                                 " is_dead_letter_message = :isDeadLetterMessage",
                                                                                                                         arg("tableName", sharedQueueTableName)))
                                                                                              .bind("id", requireNonNull(queueEntryId, "No queueEntryId provided"))
                                                                                              .bind("isDeadLetterMessage", isDeadLetterMessage)
                                                                                              .map(queuedMessageMapper)
                                                                                              .findOne());
    }

    private Object deserializeMessagePayload(QueueName queueName, QueueEntryId queueEntryId, String messagePayload, String messagePayloadType) {
        requireNonNull(queueName, "No queueName provided");
        requireNonNull(queueEntryId, "No queueEntryId provided");
        requireNonNull(messagePayload, "No messagePayload provided");
        requireNonNull(messagePayloadType, "No messagePayloadType provided");
        try {
            return jsonSerializer.deserialize(messagePayload, messagePayloadType);
        } catch (Throwable e) {
            rethrowIfCriticalError(e);
            throw new DurableQueueDeserializationException(msg("Failed to deserialize message payload of type {}", messagePayloadType), e, queueName, queueEntryId);
        }
    }

    private MessageMetaData deserializeMessageMetadata(QueueName queueName, QueueEntryId queueEntryId, String metaData) {
        requireNonNull(queueName, "No queueName provided");
        requireNonNull(queueEntryId, "No queueEntryId provided");
        requireNonNull(metaData, "No messagePayload provided");
        try {
            return jsonSerializer.deserialize(metaData, MessageMetaData.class);
        } catch (Throwable e) {
            rethrowIfCriticalError(e);
            throw new DurableQueueDeserializationException(msg("Failed to deserialize message meta-data"), e, queueName, queueEntryId);
        }
    }


    /**
     * Default {@link ObjectMapper} supporting {@link Jdk8Module}, {@link JavaTimeModule}, {@link EssentialTypesJacksonModule} and {@link EssentialsImmutableJacksonModule}, which
     * is used together with the {@link JacksonJSONSerializer}
     *
     * @return the default {@link ObjectMapper}
     */
    public static ObjectMapper createDefaultObjectMapper() {
        var objectMapper = JsonMapper.builder()
                                     .disable(MapperFeature.AUTO_DETECT_GETTERS)
                                     .disable(MapperFeature.AUTO_DETECT_IS_GETTERS)
                                     .disable(MapperFeature.AUTO_DETECT_SETTERS)
                                     .disable(MapperFeature.DEFAULT_VIEW_INCLUSION)
                                     .disable(SerializationFeature.WRITE_DATES_AS_TIMESTAMPS)
                                     .disable(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES)
                                     .disable(SerializationFeature.FAIL_ON_EMPTY_BEANS)
                                     .enable(MapperFeature.AUTO_DETECT_CREATORS)
                                     .enable(MapperFeature.AUTO_DETECT_FIELDS)
                                     .enable(MapperFeature.PROPAGATE_TRANSIENT_MARKER)
                                     .addModule(new Jdk8Module())
                                     .addModule(new JavaTimeModule())
                                     .addModule(new EssentialTypesJacksonModule())
                                     .addModule(new EssentialsImmutableJacksonModule())
                                     .build();

        objectMapper.setVisibility(objectMapper.getSerializationConfig().getDefaultVisibilityChecker()
                                               .withGetterVisibility(JsonAutoDetect.Visibility.NONE)
                                               .withSetterVisibility(JsonAutoDetect.Visibility.NONE)
                                               .withFieldVisibility(JsonAutoDetect.Visibility.ANY)
                                               .withCreatorVisibility(JsonAutoDetect.Visibility.ANY));
        return objectMapper;
    }

    private static class SingleOperationTransactionDurableQueuesInterceptor implements DurableQueuesInterceptor {
        private final HandleAwareUnitOfWorkFactory<? extends HandleAwareUnitOfWork> unitOfWorkFactory;
        private       DurableQueues                                                 durableQueues;

        public SingleOperationTransactionDurableQueuesInterceptor(HandleAwareUnitOfWorkFactory<? extends HandleAwareUnitOfWork> unitOfWorkFactory) {
            this.unitOfWorkFactory = unitOfWorkFactory;
        }

        @Override
        public void setDurableQueues(DurableQueues durableQueues) {
            this.durableQueues = requireNonNull(durableQueues, "No durableQueues instance provided");
        }

        @Override
        public Optional<QueuedMessage> intercept(GetDeadLetterMessage operation, InterceptorChain<GetDeadLetterMessage, Optional<QueuedMessage>, DurableQueuesInterceptor> interceptorChain) {
            return unitOfWorkFactory.withUnitOfWork(interceptorChain::proceed);
        }

        @Override
        public Optional<QueuedMessage> intercept(GetQueuedMessage operation, InterceptorChain<GetQueuedMessage, Optional<QueuedMessage>, DurableQueuesInterceptor> interceptorChain) {
            return unitOfWorkFactory.withUnitOfWork(interceptorChain::proceed);
        }

        @Override
        public QueueEntryId intercept(QueueMessage operation, InterceptorChain<QueueMessage, QueueEntryId, DurableQueuesInterceptor> interceptorChain) {
            return unitOfWorkFactory.withUnitOfWork(interceptorChain::proceed);
        }

        @Override
        public QueueEntryId intercept(QueueMessageAsDeadLetterMessage operation, InterceptorChain<QueueMessageAsDeadLetterMessage, QueueEntryId, DurableQueuesInterceptor> interceptorChain) {
            return unitOfWorkFactory.withUnitOfWork(interceptorChain::proceed);
        }

        @Override
        public List<QueueEntryId> intercept(QueueMessages operation, InterceptorChain<QueueMessages, List<QueueEntryId>, DurableQueuesInterceptor> interceptorChain) {
            return unitOfWorkFactory.withUnitOfWork(interceptorChain::proceed);
        }

        @Override
        public Optional<QueuedMessage> intercept(RetryMessage operation, InterceptorChain<RetryMessage, Optional<QueuedMessage>, DurableQueuesInterceptor> interceptorChain) {
            return unitOfWorkFactory.withUnitOfWork(interceptorChain::proceed);
        }

        @Override
        public Optional<QueuedMessage> intercept(MarkAsDeadLetterMessage operation, InterceptorChain<MarkAsDeadLetterMessage, Optional<QueuedMessage>, DurableQueuesInterceptor> interceptorChain) {
            return unitOfWorkFactory.withUnitOfWork(interceptorChain::proceed);
        }

        @Override
        public Optional<QueuedMessage> intercept(ResurrectDeadLetterMessage operation, InterceptorChain<ResurrectDeadLetterMessage, Optional<QueuedMessage>, DurableQueuesInterceptor> interceptorChain) {
            return unitOfWorkFactory.withUnitOfWork(interceptorChain::proceed);
        }

        @Override
        public boolean intercept(AcknowledgeMessageAsHandled operation, InterceptorChain<AcknowledgeMessageAsHandled, Boolean, DurableQueuesInterceptor> interceptorChain) {
            return unitOfWorkFactory.withUnitOfWork(interceptorChain::proceed);
        }

        @Override
        public Void intercept(HandleQueuedMessage operation, InterceptorChain<HandleQueuedMessage, Void, DurableQueuesInterceptor> interceptorChain) {
            return unitOfWorkFactory.withUnitOfWork(interceptorChain::proceed);
        }

        @Override
        public boolean intercept(DeleteMessage operation, InterceptorChain<DeleteMessage, Boolean, DurableQueuesInterceptor> interceptorChain) {
            return unitOfWorkFactory.withUnitOfWork(interceptorChain::proceed);
        }

        @Override
        public Optional<QueuedMessage> intercept(GetNextMessageReadyForDelivery operation, InterceptorChain<GetNextMessageReadyForDelivery, Optional<QueuedMessage>, DurableQueuesInterceptor> interceptorChain) {
            return unitOfWorkFactory.withUnitOfWork(interceptorChain::proceed);
        }

        @Override
        public long intercept(GetTotalMessagesQueuedFor operation, InterceptorChain<GetTotalMessagesQueuedFor, Long, DurableQueuesInterceptor> interceptorChain) {
            return unitOfWorkFactory.withUnitOfWork(interceptorChain::proceed);
        }

        @Override
        public List<QueuedMessage> intercept(GetQueuedMessages operation, InterceptorChain<GetQueuedMessages, List<QueuedMessage>, DurableQueuesInterceptor> interceptorChain) {
            return unitOfWorkFactory.withUnitOfWork(interceptorChain::proceed);
        }

        @Override
        public List<QueuedMessage> intercept(GetDeadLetterMessages operation, InterceptorChain<GetDeadLetterMessages, List<QueuedMessage>, DurableQueuesInterceptor> interceptorChain) {
            return unitOfWorkFactory.withUnitOfWork(interceptorChain::proceed);
        }

        @Override
        public int intercept(PurgeQueue operation, InterceptorChain<PurgeQueue, Integer, DurableQueuesInterceptor> interceptorChain) {
            return unitOfWorkFactory.withUnitOfWork(interceptorChain::proceed);
        }
    }

    public static class QueueTableNotification extends TableChangeNotification {
        @JsonProperty("id")
        private String id;
        @JsonProperty("queue_name")
        private String queueName;

        @JsonProperty("added_ts")
        private OffsetDateTime addedTimestamp;

        @JsonProperty("next_delivery_ts")
        private OffsetDateTime nextDeliveryTimestamp;

        @JsonProperty("delivery_ts")
        private OffsetDateTime deliveryTimestamp;

        @JsonProperty("is_dead_letter_message")
        private boolean isDeadLetterMessage;

        @JsonProperty("is_being_delivered")
        private boolean isBeingDelivered;

        public QueueTableNotification() {
        }
    }
}
